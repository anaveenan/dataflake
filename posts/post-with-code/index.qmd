---
title: "Mastering Data Manipulation in Pandas: A Guide to Key SQL Operations"
author: "Naveenan Arjunan"
date: "2024-03-02"
categories: [pandas, sql, analysis]
image: "image.jpg"

---


## About

Data is often organized in a rectangular format with rows and columns, commonly known as table data, data frames, structured data, or spreadsheets. In Python, the Pandas library is a powerful tool for manipulating such structured datasets. This blog post explores essential operations in data analysis with Pandas, aligning with SQL concepts such as selecting columns, applying conditions, grouping, aggregating, ordering, and joining datasets.

Having worked with Pandas, I noticed that while it offers numerous methods for similar tasks, the transition from SQL to Pandas can sometimes lead to less elegant and harder-to-debug code. This post aims to simplify the execution of these core SQL operations in Pandas, providing clear examples to enhance your data manipulation skills in Python.


```{python}
#| echo: true
#| warning: false
import pandas as pd
import numpy as np
df = pd.read_csv("https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv")
pd.options.display.max_rows = 20
df.head(5)
```

## Selecting columns

To select specific columns, use the .loc method with a list of column names. This approach offers flexibility in data analysis.

```{python}
(df
 .loc[:,['tip','sex']]
 .head()
)
```

To select columns starting with 't':

```{python}
(df
 .loc[:,[col for col in df.columns if col.startswith('t')]]
 .head()
)
```

## Column Manipulation

Use the `.assign` method to create or modify columns:

Add a new column with a constant value: `.assign(new_col=1)`
Add a new column based on existing columns: `.assign(new_col=lambda x: x['col'] + 1)`
Update an existing column: `.assign(old_col=lambda x: x['old_col'] + 1)`

```{python}
(df
 .loc[:,['total_bill','tip','sex','day','time']]
 .assign(percentage_tip=lambda x:x['tip']/x['total_bill']) #Add new column
 .assign(tip=lambda x:x['tip']+1) # Update existing column 
 .assign(count=1) #Add constant value 
 .head()
)
```


## Filtering Rows

Use the `.loc` method to filter rows:

```{python}
#Filter only transaction with more than 15% in tips
(df
 .loc[:,['total_bill','tip','sex','day','time']]
 .assign(percentage_tip=lambda x:x['tip']/x['total_bill'])
 .loc[lambda x:x['percentage_tip']>.15,:]
 .head()
)
```

```{python}
#Filter only transactions happend on Sunday and Monday
(df
 .loc[:,['total_bill','tip','sex','day','time']]
 .loc[lambda x:x['day'].isin(['Sun','Mon']),:]
 .head()
)
```

## Group By and Aggregation

Use groupby and agg for aggregations:

```{python}
#By day get average and total bill
(df
 .groupby(['day'])
 .agg(avg_bill=('total_bill','mean')
     ,total_bill=('total_bill','sum')) #multiple column aggregations supported
 .reset_index()
)
```


```{python}
#By day get average of total bill using : functions, lambda functions, numpy functions 
(df
 .groupby(['day'])
 .agg(avg_bill_mean=('total_bill','mean')
     ,avg_bill_lambda=('total_bill',lambda x:x.mean()) #using lambda functions
     ,avg_bill_np=('total_bill',np.mean)) #using numpy functions 
 .reset_index()
)
```

## Ordering Rows

Sort data using .sort_values:

```{python}
#By day get average and total bill.Sort the output by total_bill
(df
 .groupby(['day'])
 .agg(avg_bill=('total_bill','mean')
     ,total_bill=('total_bill','sum'))
 .reset_index()
 .sort_values(['total_bill'],ascending=False) #Default is ascending 
)
```


```{python}
#By day get average and total bill.Sort the output by total_bill and avg_bill
(df
 .groupby(['day'])
 .agg(avg_bill=('total_bill','mean')
     ,total_bill=('total_bill','sum'))
 .reset_index()
 .sort_values(['total_bill','avg_bill'],ascending=[False,True]) #By multiple columns one by asc and other by desc
)
```

## Window Functions

Perform advanced data manipulation with window functions:

```{python}
#Equivalent of row_number() over(partition by day order by total_bill asc) as row_number
(df
 .assign(row_number=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day']).cumcount()+1)
 .sort_values(['row_number'])
 .head()
)
```

Calculate lead and lag values:
```{python}
#Equivalent of lag(total_bill) over(partition by day order by total_bill asc) as previous_bill
(df
 .assign(row_number=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day']).cumcount()+1)
 .assign(prev_bill=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day'])['total_bill'].shift(1))
 .sort_values(['row_number'])
 .head()
)
```


```{python}
#Equivalent of lead(total_bill) over(partition by day order by total_bill asc) as previous_bill
(df
 .assign(row_number=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day']).cumcount()+1)
 .assign(next_bill=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day'])['total_bill'].shift(-1))
 .sort_values(['row_number'])
 .head()
)
```


```{python}
#Equivalent of sum(total_bill) over(partition by day) as sum_bill_day
#Equivalent of sum(tip) over(partition by day order by total_bill asc) as cum_tip_day
#Equivalent of sum(tip) over(partition by day order by total_bill rows between 3 preceeding and current row) as rolling_3d_sum 

(df
 .assign(sum_bill_day=lambda x:x.groupby(['day'])['total_bill'].transform('sum'))
 .assign(cum_tip_day=lambda x:x.sort_values(['total_bill']).groupby(['day'])['tip'].cumsum())
 .assign(rolling_3d_sum=lambda x:x.sort_values(['total_bill']).groupby(['day'])['tip'].rolling(window=2,min_periods=1).sum().reset_index(drop=True, level=0))
 .query("day=='Sat'")
 .sort_values(['total_bill'])
 .head()
)
```

## Conclusion

This post provides fundamental strategies for effective data analysis with Pandas. Future updates will include additional examples to further simplify data analysis using Pandas.