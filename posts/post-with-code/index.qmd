---
title: "Pandas Mastery: SQL Operations Made Easy"
author: "Naveenan Arjunan"
date: "2024-03-02"
categories: [pandas, sql, analysis]
image: "image.jpg"
jupyter: python3

---

## Introduction

Data analysis often involves working with structured datasets organized in rows and columns. While SQL has long been the go-to language for manipulating such data, Python's Pandas library offers comparable functionality with added flexibility. This post explores how to perform essential SQL-like operations in Pandas, providing a bridge for analysts transitioning between these two powerful tools. 

## Setting Up the Environment

Let's begin by importing the necessary libraries and loading our dataset:

```{python}
import pandas as pd
import numpy as np
pd.options.display.max_rows = 20
df = pd.read_csv("https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv")
df.head(5)
```



## About

Data is often organized in a rectangular format with rows and columns, commonly known as table data, data frames, structured data, or spreadsheets. In Python, the Pandas library is a powerful tool for manipulating such structured datasets. This blog post explores essential operations in data analysis with Pandas, aligning with SQL concepts such as selecting columns, applying conditions, grouping, aggregating, ordering, and joining datasets.

Having worked with Pandas, I noticed that while it offers numerous methods for similar tasks, the transition from SQL to Pandas can sometimes lead to less elegant and harder-to-debug code. This post aims to simplify the execution of these core SQL operations in Pandas, providing clear examples to enhance your data manipulation skills in Python.


```{python}
#| echo: true
#| warning: false
import pandas as pd
import numpy as np
df = pd.read_csv("https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv")
pd.options.display.max_rows = 20
df.head(5)
```

## Selecting columns

In Pandas, column selection is straightforward using the .loc accessor:

```{python}
(df
 .loc[:,['tip','sex']] # ①
 .head() 
)
```

For more dynamic selection, we can use list comprehensions:

```{python}
(df
 .loc[:,[col for col in df.columns if col.startswith('t')]] # ②
 .head() 
)
```


In the code above, ① demonstrates basic column selection, while ② shows a more advanced technique using a list comprehension. This method ② is particularly useful when you need to select columns based on a specific condition, such as all columns starting with a certain letter.

## Column Manipulation

Use the `.assign` method to create or modify columns:

```{python}
(df
 .loc[:, ['total_bill', 'tip', 'sex', 'day', 'time']]
 .assign(percentage_tip=lambda x: x['tip'] / x['total_bill'])  # ①
 .assign(tip=lambda x: x['tip'] + 1)  # ②
 .assign(count=1)  # ③
 .head()
)
```

Here, ① calculates a new column, ② modifies an existing column, and ③ adds a constant value column. This demonstrates the versatility of assign() in performing various column operations in a single chain.

## Filtering Rows

Use the `.loc` method to filter rows:

```{python}
#Filter only transaction with more than 15% in tips
(df
 .loc[:,['total_bill','tip','sex','day','time']]
 .assign(percentage_tip=lambda x:x['tip']/x['total_bill'])
 .loc[lambda x:x['percentage_tip']>.15,:] # ①
 .head()
)
```

The filter condition ① uses a lambda function within .loc[] to select rows where the tip percentage exceeds 15%. This approach provides a clean, SQL-like syntax for row filtering.

```{python}
#Filter only transactions happend on Sunday and Monday
(df
 .loc[:,['total_bill','tip','sex','day','time']]
 .loc[lambda x:x['day'].isin(['Sun','Mon']),:]
 .head()
)
```

## Grouping and Aggregation

Pandas offers powerful grouping and aggregation capabilities:

```{python}
(df
 .groupby(['day'])  # ①
 .agg(avg_bill=('total_bill', 'mean'),  # ②
      total_bill=('total_bill', 'sum'))
 .reset_index()
)
```

In this example, ① groups the data by the 'day' column, and ② applies multiple aggregations. The agg() method allows for clear specification of column names and aggregation functions, similar to SQL's GROUP BY and aggregate functions.

```{python}
#By day get average of total bill using : functions, lambda functions, numpy functions 
(df
 .groupby(['day'])
 .agg(avg_bill_mean=('total_bill','mean')
     ,avg_bill_lambda=('total_bill',lambda x:x.mean()) #using lambda functions
     ,avg_bill_np=('total_bill',np.mean)) #using numpy functions 
 .reset_index()
)
```

## Ordering Rows

Sorting data in Pandas is achieved using the .sort_values method:

```{python}
#By day get average and total bill.Sort the output by total_bill
(df
 .groupby(['day'])
 .agg(avg_bill=('total_bill','mean')
     ,total_bill=('total_bill','sum'))
 .reset_index()
 .sort_values(['total_bill'],ascending=[False]) # ①
)
```

The sorting operation ① is equivalent to SQL's ORDER BY clause. It allows for sorting by multiple columns and specifying the sort order (ascending or descending).

## Window Functions

Pandas can replicate complex SQL window functions:

::: {.callout-note}
Window functions in Pandas, while powerful, can be complex. They offer advanced data manipulation capabilities similar to those in SQL.
:::
```{python}
(df
 .assign(row_number=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day']).cumcount()+1)  # ①
 .assign(prev_bill=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day'])['total_bill'].shift(1)) # ②
 .assign(next_bill=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day'])['total_bill'].shift(-1)) # 
 .sort_values(['row_number'])
 .head()
)
```

Here, ① creates a row number within each day group, sorted by total bill, similar to SQL's ROW_NUMBER() function. ② calculates the previous bill amount within each day group, mimicking SQL's LAG() function. ③ computes the next bill amount within each day group, equivalent to SQL's LEAD() function.

```{python}
(df
 .assign(sum_bill_day=lambda x:x.groupby(['day'])['total_bill'].transform('sum')) # ④
 .assign(cum_tip_day=lambda x:x.sort_values(['total_bill']).groupby(['day'])['tip'].cumsum()) # ⑤
 .assign(rolling_3d_sum=lambda x:x.sort_values(['total_bill']).groupby(['day'])['tip'].rolling(window=2,min_periods=1).sum().reset_index(drop=True, level=0)) # ⑥
 .query("day=='Sat'")
 .sort_values(['total_bill'])
 .head()
)
```

④ Calculates the sum of total bills for each day, equivalent to SUM(total_bill) OVER (PARTITION BY day) in SQL.
⑤ Computes the cumulative sum of tips within each day, ordered by total bill. This is similar to SUM(tip) OVER (PARTITION BY day ORDER BY total_bill ASC) in SQL.
⑥ Performs a rolling sum of tips over a 2-row window (current row and 1 preceding) within each day, ordered by total bill. This complex operation is akin to SUM(tip) OVER (PARTITION BY day ORDER BY total_bill ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) in SQL.


## Conclusion

This guide demonstrates how Pandas can effectively replicate key SQL operations. By mastering these techniques, analysts can seamlessly transition between SQL and Pandas, choosing the most appropriate tool for their specific data analysis needs.