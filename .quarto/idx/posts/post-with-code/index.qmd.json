{"title":"Pandas Mastery: SQL Operations Made Easy","markdown":{"yaml":{"title":"Pandas Mastery: SQL Operations Made Easy","author":"Naveenan Arjunan","date":"2024-03-02","categories":["pandas","sql","analysis"],"image":"image.jpg","jupyter":"python3"},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n\nData analysis often involves working with structured datasets organized in rows and columns. While SQL has long been the go-to language for manipulating such data, Python's Pandas library offers comparable functionality with added flexibility. This post explores how to perform essential SQL-like operations in Pandas, providing a bridge for analysts transitioning between these two powerful tools. \n\n## Setting Up the Environment\n\nLet's begin by importing the necessary libraries and loading our dataset:\n\n```{python}\nimport pandas as pd\nimport numpy as np\npd.options.display.max_rows = 20\ndf = pd.read_csv(\"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv\")\ndf.head(5)\n```\n\n\n\n## About\n\nData is often organized in a rectangular format with rows and columns, commonly known as table data, data frames, structured data, or spreadsheets. In Python, the Pandas library is a powerful tool for manipulating such structured datasets. This blog post explores essential operations in data analysis with Pandas, aligning with SQL concepts such as selecting columns, applying conditions, grouping, aggregating, ordering, and joining datasets.\n\nHaving worked with Pandas, I noticed that while it offers numerous methods for similar tasks, the transition from SQL to Pandas can sometimes lead to less elegant and harder-to-debug code. This post aims to simplify the execution of these core SQL operations in Pandas, providing clear examples to enhance your data manipulation skills in Python.\n\n\n```{python}\n#| echo: true\n#| warning: false\nimport pandas as pd\nimport numpy as np\ndf = pd.read_csv(\"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv\")\npd.options.display.max_rows = 20\ndf.head(5)\n```\n\n## Selecting columns\n\nIn Pandas, column selection is straightforward using the .loc accessor:\n\n```{python}\n(df\n .loc[:,['tip','sex']] # ①\n .head() \n)\n```\n\nFor more dynamic selection, we can use list comprehensions:\n\n```{python}\n(df\n .loc[:,[col for col in df.columns if col.startswith('t')]] # ②\n .head() \n)\n```\n\n\nIn the code above, ① demonstrates basic column selection, while ② shows a more advanced technique using a list comprehension. This method ② is particularly useful when you need to select columns based on a specific condition, such as all columns starting with a certain letter.\n\n## Column Manipulation\n\nUse the `.assign` method to create or modify columns:\n\n```{python}\n(df\n .loc[:, ['total_bill', 'tip', 'sex', 'day', 'time']]\n .assign(percentage_tip=lambda x: x['tip'] / x['total_bill'])  # ①\n .assign(tip=lambda x: x['tip'] + 1)  # ②\n .assign(count=1)  # ③\n .head()\n)\n```\n\nHere, ① calculates a new column, ② modifies an existing column, and ③ adds a constant value column. This demonstrates the versatility of assign() in performing various column operations in a single chain.\n\n## Filtering Rows\n\nUse the `.loc` method to filter rows:\n\n```{python}\n#Filter only transaction with more than 15% in tips\n(df\n .loc[:,['total_bill','tip','sex','day','time']]\n .assign(percentage_tip=lambda x:x['tip']/x['total_bill'])\n .loc[lambda x:x['percentage_tip']>.15,:] # ①\n .head()\n)\n```\n\nThe filter condition ① uses a lambda function within .loc[] to select rows where the tip percentage exceeds 15%. This approach provides a clean, SQL-like syntax for row filtering.\n\n```{python}\n#Filter only transactions happend on Sunday and Monday\n(df\n .loc[:,['total_bill','tip','sex','day','time']]\n .loc[lambda x:x['day'].isin(['Sun','Mon']),:]\n .head()\n)\n```\n\n## Grouping and Aggregation\n\nPandas offers powerful grouping and aggregation capabilities:\n\n```{python}\n(df\n .groupby(['day'])  # ①\n .agg(avg_bill=('total_bill', 'mean'),  # ②\n      total_bill=('total_bill', 'sum'))\n .reset_index()\n)\n```\n\nIn this example, ① groups the data by the 'day' column, and ② applies multiple aggregations. The agg() method allows for clear specification of column names and aggregation functions, similar to SQL's GROUP BY and aggregate functions.\n\n```{python}\n#By day get average of total bill using : functions, lambda functions, numpy functions \n(df\n .groupby(['day'])\n .agg(avg_bill_mean=('total_bill','mean')\n     ,avg_bill_lambda=('total_bill',lambda x:x.mean()) #using lambda functions\n     ,avg_bill_np=('total_bill',np.mean)) #using numpy functions \n .reset_index()\n)\n```\n\n## Ordering Rows\n\nSorting data in Pandas is achieved using the .sort_values method:\n\n```{python}\n#By day get average and total bill.Sort the output by total_bill\n(df\n .groupby(['day'])\n .agg(avg_bill=('total_bill','mean')\n     ,total_bill=('total_bill','sum'))\n .reset_index()\n .sort_values(['total_bill'],ascending=[False]) # ①\n)\n```\n\nThe sorting operation ① is equivalent to SQL's ORDER BY clause. It allows for sorting by multiple columns and specifying the sort order (ascending or descending).\n\n## Window Functions\n\nPandas can replicate complex SQL window functions:\n\n::: {.callout-note}\nWindow functions in Pandas, while powerful, can be complex. They offer advanced data manipulation capabilities similar to those in SQL.\n:::\n```{python}\n(df\n .assign(row_number=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day']).cumcount()+1)  # ①\n .assign(prev_bill=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day'])['total_bill'].shift(1)) # ②\n .assign(next_bill=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day'])['total_bill'].shift(-1)) # \n .sort_values(['row_number'])\n .head()\n)\n```\n\nHere, ① creates a row number within each day group, sorted by total bill, similar to SQL's ROW_NUMBER() function. ② calculates the previous bill amount within each day group, mimicking SQL's LAG() function. ③ computes the next bill amount within each day group, equivalent to SQL's LEAD() function.\n\n```{python}\n(df\n .assign(sum_bill_day=lambda x:x.groupby(['day'])['total_bill'].transform('sum')) # ④\n .assign(cum_tip_day=lambda x:x.sort_values(['total_bill']).groupby(['day'])['tip'].cumsum()) # ⑤\n .assign(rolling_3d_sum=lambda x:x.sort_values(['total_bill']).groupby(['day'])['tip'].rolling(window=2,min_periods=1).sum().reset_index(drop=True, level=0)) # ⑥\n .query(\"day=='Sat'\")\n .sort_values(['total_bill'])\n .head()\n)\n```\n\n④ Calculates the sum of total bills for each day, equivalent to SUM(total_bill) OVER (PARTITION BY day) in SQL.\n⑤ Computes the cumulative sum of tips within each day, ordered by total bill. This is similar to SUM(tip) OVER (PARTITION BY day ORDER BY total_bill ASC) in SQL.\n⑥ Performs a rolling sum of tips over a 2-row window (current row and 1 preceding) within each day, ordered by total bill. This complex operation is akin to SUM(tip) OVER (PARTITION BY day ORDER BY total_bill ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) in SQL.\n\n\n## Conclusion\n\nThis guide demonstrates how Pandas can effectively replicate key SQL operations. By mastering these techniques, analysts can seamlessly transition between SQL and Pandas, choosing the most appropriate tool for their specific data analysis needs.","srcMarkdownNoYaml":"\n\n## Introduction\n\nData analysis often involves working with structured datasets organized in rows and columns. While SQL has long been the go-to language for manipulating such data, Python's Pandas library offers comparable functionality with added flexibility. This post explores how to perform essential SQL-like operations in Pandas, providing a bridge for analysts transitioning between these two powerful tools. \n\n## Setting Up the Environment\n\nLet's begin by importing the necessary libraries and loading our dataset:\n\n```{python}\nimport pandas as pd\nimport numpy as np\npd.options.display.max_rows = 20\ndf = pd.read_csv(\"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv\")\ndf.head(5)\n```\n\n\n\n## About\n\nData is often organized in a rectangular format with rows and columns, commonly known as table data, data frames, structured data, or spreadsheets. In Python, the Pandas library is a powerful tool for manipulating such structured datasets. This blog post explores essential operations in data analysis with Pandas, aligning with SQL concepts such as selecting columns, applying conditions, grouping, aggregating, ordering, and joining datasets.\n\nHaving worked with Pandas, I noticed that while it offers numerous methods for similar tasks, the transition from SQL to Pandas can sometimes lead to less elegant and harder-to-debug code. This post aims to simplify the execution of these core SQL operations in Pandas, providing clear examples to enhance your data manipulation skills in Python.\n\n\n```{python}\n#| echo: true\n#| warning: false\nimport pandas as pd\nimport numpy as np\ndf = pd.read_csv(\"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv\")\npd.options.display.max_rows = 20\ndf.head(5)\n```\n\n## Selecting columns\n\nIn Pandas, column selection is straightforward using the .loc accessor:\n\n```{python}\n(df\n .loc[:,['tip','sex']] # ①\n .head() \n)\n```\n\nFor more dynamic selection, we can use list comprehensions:\n\n```{python}\n(df\n .loc[:,[col for col in df.columns if col.startswith('t')]] # ②\n .head() \n)\n```\n\n\nIn the code above, ① demonstrates basic column selection, while ② shows a more advanced technique using a list comprehension. This method ② is particularly useful when you need to select columns based on a specific condition, such as all columns starting with a certain letter.\n\n## Column Manipulation\n\nUse the `.assign` method to create or modify columns:\n\n```{python}\n(df\n .loc[:, ['total_bill', 'tip', 'sex', 'day', 'time']]\n .assign(percentage_tip=lambda x: x['tip'] / x['total_bill'])  # ①\n .assign(tip=lambda x: x['tip'] + 1)  # ②\n .assign(count=1)  # ③\n .head()\n)\n```\n\nHere, ① calculates a new column, ② modifies an existing column, and ③ adds a constant value column. This demonstrates the versatility of assign() in performing various column operations in a single chain.\n\n## Filtering Rows\n\nUse the `.loc` method to filter rows:\n\n```{python}\n#Filter only transaction with more than 15% in tips\n(df\n .loc[:,['total_bill','tip','sex','day','time']]\n .assign(percentage_tip=lambda x:x['tip']/x['total_bill'])\n .loc[lambda x:x['percentage_tip']>.15,:] # ①\n .head()\n)\n```\n\nThe filter condition ① uses a lambda function within .loc[] to select rows where the tip percentage exceeds 15%. This approach provides a clean, SQL-like syntax for row filtering.\n\n```{python}\n#Filter only transactions happend on Sunday and Monday\n(df\n .loc[:,['total_bill','tip','sex','day','time']]\n .loc[lambda x:x['day'].isin(['Sun','Mon']),:]\n .head()\n)\n```\n\n## Grouping and Aggregation\n\nPandas offers powerful grouping and aggregation capabilities:\n\n```{python}\n(df\n .groupby(['day'])  # ①\n .agg(avg_bill=('total_bill', 'mean'),  # ②\n      total_bill=('total_bill', 'sum'))\n .reset_index()\n)\n```\n\nIn this example, ① groups the data by the 'day' column, and ② applies multiple aggregations. The agg() method allows for clear specification of column names and aggregation functions, similar to SQL's GROUP BY and aggregate functions.\n\n```{python}\n#By day get average of total bill using : functions, lambda functions, numpy functions \n(df\n .groupby(['day'])\n .agg(avg_bill_mean=('total_bill','mean')\n     ,avg_bill_lambda=('total_bill',lambda x:x.mean()) #using lambda functions\n     ,avg_bill_np=('total_bill',np.mean)) #using numpy functions \n .reset_index()\n)\n```\n\n## Ordering Rows\n\nSorting data in Pandas is achieved using the .sort_values method:\n\n```{python}\n#By day get average and total bill.Sort the output by total_bill\n(df\n .groupby(['day'])\n .agg(avg_bill=('total_bill','mean')\n     ,total_bill=('total_bill','sum'))\n .reset_index()\n .sort_values(['total_bill'],ascending=[False]) # ①\n)\n```\n\nThe sorting operation ① is equivalent to SQL's ORDER BY clause. It allows for sorting by multiple columns and specifying the sort order (ascending or descending).\n\n## Window Functions\n\nPandas can replicate complex SQL window functions:\n\n::: {.callout-note}\nWindow functions in Pandas, while powerful, can be complex. They offer advanced data manipulation capabilities similar to those in SQL.\n:::\n```{python}\n(df\n .assign(row_number=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day']).cumcount()+1)  # ①\n .assign(prev_bill=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day'])['total_bill'].shift(1)) # ②\n .assign(next_bill=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day'])['total_bill'].shift(-1)) # \n .sort_values(['row_number'])\n .head()\n)\n```\n\nHere, ① creates a row number within each day group, sorted by total bill, similar to SQL's ROW_NUMBER() function. ② calculates the previous bill amount within each day group, mimicking SQL's LAG() function. ③ computes the next bill amount within each day group, equivalent to SQL's LEAD() function.\n\n```{python}\n(df\n .assign(sum_bill_day=lambda x:x.groupby(['day'])['total_bill'].transform('sum')) # ④\n .assign(cum_tip_day=lambda x:x.sort_values(['total_bill']).groupby(['day'])['tip'].cumsum()) # ⑤\n .assign(rolling_3d_sum=lambda x:x.sort_values(['total_bill']).groupby(['day'])['tip'].rolling(window=2,min_periods=1).sum().reset_index(drop=True, level=0)) # ⑥\n .query(\"day=='Sat'\")\n .sort_values(['total_bill'])\n .head()\n)\n```\n\n④ Calculates the sum of total bills for each day, equivalent to SUM(total_bill) OVER (PARTITION BY day) in SQL.\n⑤ Computes the cumulative sum of tips within each day, ordered by total bill. This is similar to SUM(tip) OVER (PARTITION BY day ORDER BY total_bill ASC) in SQL.\n⑥ Performs a rolling sum of tips over a 2-row window (current row and 1 preceding) within each day, ordered by total bill. This complex operation is akin to SUM(tip) OVER (PARTITION BY day ORDER BY total_bill ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) in SQL.\n\n\n## Conclusion\n\nThis guide demonstrates how Pandas can effectively replicate key SQL operations. By mastering these techniques, analysts can seamlessly transition between SQL and Pandas, choosing the most appropriate tool for their specific data analysis needs."},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.550","theme":"pulse","title-block-banner":true,"title":"Pandas Mastery: SQL Operations Made Easy","author":"Naveenan Arjunan","date":"2024-03-02","categories":["pandas","sql","analysis"],"image":"image.jpg","jupyter":"python3"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}