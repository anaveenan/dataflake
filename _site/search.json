[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Pandas Mastery: SQL Operations Made Easy",
    "section": "",
    "text": "Data analysis often involves working with structured datasets organized in rows and columns. While SQL has long been the go-to language for manipulating such data, Python’s Pandas library offers comparable functionality with added flexibility. This post explores how to perform essential SQL-like operations in Pandas, providing a bridge for analysts transitioning between these two powerful tools."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DataFlake",
    "section": "",
    "text": "Pandas Mastery: SQL Operations Made Easy\n\n\n\n\n\n\npandas\n\n\nsql\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nMar 2, 2024\n\n\nNaveenan Arjunan\n\n\n\n\n\n\n\n\n\n\n\n\nDecorators\n\n\n\n\n\n\npython\n\n\nadvanced-python\n\n\n\n\n\n\n\n\n\nMar 2, 2024\n\n\nNaveenan Arjunan\n\n\n\n\n\n\n\n\n\n\n\n\nDecorators\n\n\n\n\n\n\npython\n\n\nA/B testing\n\n\ndatascience\n\n\n\n\n\n\n\n\n\nMar 2, 2024\n\n\nNaveenan Arjunan\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nFeb 28, 2024\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html#about",
    "href": "posts/post-with-code/index.html#about",
    "title": "Pandas Mastery: SQL Operations Made Easy",
    "section": "About",
    "text": "About\nData is often organized in a rectangular format with rows and columns, commonly known as table data, data frames, structured data, or spreadsheets. In Python, the Pandas library is a powerful tool for manipulating such structured datasets. This blog post explores essential operations in data analysis with Pandas, aligning with SQL concepts such as selecting columns, applying conditions, grouping, aggregating, ordering, and joining datasets.\nHaving worked with Pandas, I noticed that while it offers numerous methods for similar tasks, the transition from SQL to Pandas can sometimes lead to less elegant and harder-to-debug code. This post aims to simplify the execution of these core SQL operations in Pandas, providing clear examples to enhance your data manipulation skills in Python.\n\nimport pandas as pd\nimport numpy as np\ndf = pd.read_csv(\"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv\")\npd.options.display.max_rows = 20\ndf.head(5)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4"
  },
  {
    "objectID": "posts/post-with-code/index.html#data-preparation",
    "href": "posts/post-with-code/index.html#data-preparation",
    "title": "Audience Splitting in A/B Experiments",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nLets create a spark session connected to local server.\nLets create a dummy dataset with 100,000 customers along with gender information.\nAdd uuid column to the dataframe to uniquely identify a user.\nConvert pandas dataframe to a spark dataframe\nRegister the spark dataframe as “user_table” to be accessed in Hive\n\n\nprint (\"hello world\")\n\nhello world"
  },
  {
    "objectID": "posts/post-with-code/index.html#select-columns",
    "href": "posts/post-with-code/index.html#select-columns",
    "title": "The Pandas Reference",
    "section": "Select columns",
    "text": "Select columns\nTo select specific columns, employ the .loc method combined with a list of the column names you wish to include. I suggest adopting this approach because it grants enhanced flexibility for your data analysis endeavors.\n.loc[:,['col1','col2']]\nFor example, to extract the total_bill and tips columns from your dataset, utilize method chaining to execute these operations sequentially. This technique allows for a streamlined and efficient workflow.\n\n(df\n .loc[:,['tip','sex']]\n .head()\n)\n\n\n\n\n\n\n\n\n\ntip\nsex\n\n\n\n\n0\n1.01\nFemale\n\n\n1\n1.66\nMale\n\n\n2\n3.50\nMale\n\n\n3\n3.31\nMale\n\n\n4\n3.61\nFemale\n\n\n\n\n\n\n\n\nSelect columns that begin with the letter ‘t’ by employing a straightforward and intelligible syntax. This method simplifies executing complex selection tasks in Pandas, making your data analysis more efficient.\n\n(df\n .loc[:,[col for col in df.columns if col.startswith('t')]]\n .head()\n)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\ntime\n\n\n\n\n0\n16.99\n1.01\nDinner\n\n\n1\n10.34\n1.66\nDinner\n\n\n2\n21.01\n3.50\nDinner\n\n\n3\n23.68\n3.31\nDinner\n\n\n4\n24.59\n3.61\nDinner"
  },
  {
    "objectID": "posts/post-with-code/index.html#select-columns-manipulation",
    "href": "posts/post-with-code/index.html#select-columns-manipulation",
    "title": "The Pandas Reference",
    "section": "Select columns manipulation",
    "text": "Select columns manipulation\nTo create new columns or modify existing ones, the .assign method is your go-to. This approach not only allows for the addition of new columns but also the updating of existing ones in a concise manner.\nTo add a new column with a constant value .assign(new_col=1) To introduce a new column based on operations with existing columns: .assign(new_col=lambda x:x['col']+1) To update an existing column by modifying its values: .assign(old_col=lambda x:x['old_col']+1)\n\n(df\n .loc[:,['total_bill','tip','sex','day','time']]\n .assign(percentage_tip=lambda x:x['tip']/x['total_bill']) #add new column\n .assign(tip=lambda x:x['tip']+1) # update existing column \n .assign(count=1) #add constant value \n .head()\n)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nday\ntime\npercentage_tip\ncount\n\n\n\n\n0\n16.99\n2.01\nFemale\nSun\nDinner\n0.059447\n1\n\n\n1\n10.34\n2.66\nMale\nSun\nDinner\n0.160542\n1\n\n\n2\n21.01\n4.50\nMale\nSun\nDinner\n0.166587\n1\n\n\n3\n23.68\n4.31\nMale\nSun\nDinner\n0.139780\n1\n\n\n4\n24.59\n4.61\nFemale\nSun\nDinner\n0.146808\n1"
  },
  {
    "objectID": "posts/post-with-code/index.html#filter-rows-where",
    "href": "posts/post-with-code/index.html#filter-rows-where",
    "title": "The Pandas Reference",
    "section": "Filter rows (where)",
    "text": "Filter rows (where)\nUtilize the query method to filter row in a pandas Dataframe\nval=10 .query(\"col1&gt;='10'\") .query(\"col1&gt;='@val'\") .query(f\"col1&gt;='{val}'\") .query(\"col1.isin(['a','b'])\",engine='python')\n\n#filter only transaction with more than 15% in tips\n(df\n .loc[:,['total_bill','tip','sex','day','time']]\n .assign(percentage_tip=lambda x:x['tip']/x['total_bill'])\n .query(\"percentage_tip&gt;.15\")\n .head()\n)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nday\ntime\npercentage_tip\n\n\n\n\n1\n10.34\n1.66\nMale\nSun\nDinner\n0.160542\n\n\n2\n21.01\n3.50\nMale\nSun\nDinner\n0.166587\n\n\n5\n25.29\n4.71\nMale\nSun\nDinner\n0.186240\n\n\n6\n8.77\n2.00\nMale\nSun\nDinner\n0.228050\n\n\n9\n14.78\n3.23\nMale\nSun\nDinner\n0.218539\n\n\n\n\n\n\n\n\n\nper_tip=.15\n#using @ within query to refer a variable in the filter \nprint(\"\")\ndisplay(df\n .loc[:,['total_bill','tip','sex','day','time']]\n .assign(percentage_tip=lambda x:x['tip']/x['total_bill'])\n .query(\"percentage_tip&gt;@per_tip\")\n .head()\n)\n\n#using f-string to perform filtering\ndisplay(df\n .loc[:,['total_bill','tip','sex','day','time']]\n .assign(percentage_tip=lambda x:x['tip']/x['total_bill'])\n .query(f\"percentage_tip&gt;{per_tip}\")\n .head()\n)\n\n\n\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nday\ntime\npercentage_tip\n\n\n\n\n1\n10.34\n1.66\nMale\nSun\nDinner\n0.160542\n\n\n2\n21.01\n3.50\nMale\nSun\nDinner\n0.166587\n\n\n5\n25.29\n4.71\nMale\nSun\nDinner\n0.186240\n\n\n6\n8.77\n2.00\nMale\nSun\nDinner\n0.228050\n\n\n9\n14.78\n3.23\nMale\nSun\nDinner\n0.218539\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nday\ntime\npercentage_tip\n\n\n\n\n1\n10.34\n1.66\nMale\nSun\nDinner\n0.160542\n\n\n2\n21.01\n3.50\nMale\nSun\nDinner\n0.166587\n\n\n5\n25.29\n4.71\nMale\nSun\nDinner\n0.186240\n\n\n6\n8.77\n2.00\nMale\nSun\nDinner\n0.228050\n\n\n9\n14.78\n3.23\nMale\nSun\nDinner\n0.218539\n\n\n\n\n\n\n\n\n\n#Filter only transactions happend on Sunday and Monday\n(df\n .loc[:,['total_bill','tip','sex','day','time']]\n .query(\"day.isin(['Sun','Mon'])\",engine='python')\n .head()\n)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nday\ntime\n\n\n\n\n0\n16.99\n1.01\nFemale\nSun\nDinner\n\n\n1\n10.34\n1.66\nMale\nSun\nDinner\n\n\n2\n21.01\n3.50\nMale\nSun\nDinner\n\n\n3\n23.68\n3.31\nMale\nSun\nDinner\n\n\n4\n24.59\n3.61\nFemale\nSun\nDinner"
  },
  {
    "objectID": "posts/post-with-code/index.html#group-by-and-aggregation",
    "href": "posts/post-with-code/index.html#group-by-and-aggregation",
    "title": "Mastering Data Manipulation in Pandas: A Guide to Key SQL Operations",
    "section": "Group By and Aggregation",
    "text": "Group By and Aggregation\nUse groupby and agg for aggregations:\n\n#By day get average and total bill\n(df\n .groupby(['day'])\n .agg(avg_bill=('total_bill','mean')\n     ,total_bill=('total_bill','sum')) #multiple column aggregations supported\n .reset_index()\n)\n\n\n\n\n\n\n\n\n\nday\navg_bill\ntotal_bill\n\n\n\n\n0\nFri\n17.151579\n325.88\n\n\n1\nSat\n20.441379\n1778.40\n\n\n2\nSun\n21.410000\n1627.16\n\n\n3\nThur\n17.682742\n1096.33\n\n\n\n\n\n\n\n\n\n#By day get average of total bill using : functions, lambda functions, numpy functions \n(df\n .groupby(['day'])\n .agg(avg_bill_mean=('total_bill','mean')\n     ,avg_bill_lambda=('total_bill',lambda x:x.mean()) #using lambda functions\n     ,avg_bill_np=('total_bill',np.mean)) #using numpy functions \n .reset_index()\n)\n\n/var/folders/_m/75zm23zj7ps40gd_wwbvgfxh0000gn/T/ipykernel_60230/586994573.py:2: FutureWarning:\n\nThe provided callable &lt;function mean at 0x7fb018630ca0&gt; is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n\n\n\n\n\n\n\n\n\n\n\nday\navg_bill_mean\navg_bill_lambda\navg_bill_np\n\n\n\n\n0\nFri\n17.151579\n17.151579\n17.151579\n\n\n1\nSat\n20.441379\n20.441379\n20.441379\n\n\n2\nSun\n21.410000\n21.410000\n21.410000\n\n\n3\nThur\n17.682742\n17.682742\n17.682742"
  },
  {
    "objectID": "posts/post-with-code/index.html#ordering-rows",
    "href": "posts/post-with-code/index.html#ordering-rows",
    "title": "Pandas Mastery: SQL Operations Made Easy",
    "section": "Ordering Rows",
    "text": "Ordering Rows\nSorting data in Pandas is achieved using the .sort_values method:\n\n#By day get average and total bill.Sort the output by total_bill\n(df\n .groupby(['day'])\n .agg(avg_bill=('total_bill','mean')\n     ,total_bill=('total_bill','sum'))\n .reset_index()\n .sort_values(['total_bill'],ascending=[False]) # ①\n)\n\n\n\n\n\n\n\n\n\nday\navg_bill\ntotal_bill\n\n\n\n\n1\nSat\n20.441379\n1778.40\n\n\n2\nSun\n21.410000\n1627.16\n\n\n3\nThur\n17.682742\n1096.33\n\n\n0\nFri\n17.151579\n325.88\n\n\n\n\n\n\n\n\nThe sorting operation ① is equivalent to SQL’s ORDER BY clause. It allows for sorting by multiple columns and specifying the sort order (ascending or descending)."
  },
  {
    "objectID": "posts/post-with-code/index.html#window-function",
    "href": "posts/post-with-code/index.html#window-function",
    "title": "The Pandas Reference",
    "section": "Window function",
    "text": "Window function\nWindow functions in SQL offering advanced data manipulation capabilities. We will explore how to utilize key functions such as row_number(), LEAD()/LAG(), and calculate a running sum within each group (partition).\n\n#Equivalent of row_number() over(partition by day order by total_bill asc) as row_number\n(df\n .assign(row_number=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day']).cumcount()+1)\n .sort_values(['row_number'])\n .head()\n)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nrow_number\n\n\n\n\n67\n3.07\n1.00\nFemale\nYes\nSat\nDinner\n1\n1\n\n\n172\n7.25\n5.15\nMale\nYes\nSun\nDinner\n2\n1\n\n\n149\n7.51\n2.00\nMale\nNo\nThur\nLunch\n2\n1\n\n\n92\n5.75\n1.00\nFemale\nYes\nFri\nDinner\n2\n1\n\n\n222\n8.58\n1.92\nMale\nYes\nFri\nLunch\n1\n2\n\n\n\n\n\n\n\n\n\n#Equivalent of lag(total_bill) over(partition by day order by total_bill asc) as previous_bill\n(df\n .assign(row_number=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day']).cumcount()+1)\n .assign(prev_bill=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day'])['total_bill'].shift(1))\n .sort_values(['row_number'])\n .head()\n)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nrow_number\nprev_bill\n\n\n\n\n67\n3.07\n1.00\nFemale\nYes\nSat\nDinner\n1\n1\nNaN\n\n\n172\n7.25\n5.15\nMale\nYes\nSun\nDinner\n2\n1\nNaN\n\n\n149\n7.51\n2.00\nMale\nNo\nThur\nLunch\n2\n1\nNaN\n\n\n92\n5.75\n1.00\nFemale\nYes\nFri\nDinner\n2\n1\nNaN\n\n\n222\n8.58\n1.92\nMale\nYes\nFri\nLunch\n1\n2\n5.75\n\n\n\n\n\n\n\n\n\n#Equivalent of lead(total_bill) over(partition by day order by total_bill asc) as previous_bill\n(df\n .assign(row_number=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day']).cumcount()+1)\n .assign(next_bill=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day'])['total_bill'].shift(-1))\n .sort_values(['row_number'])\n .head()\n)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nrow_number\nnext_bill\n\n\n\n\n67\n3.07\n1.00\nFemale\nYes\nSat\nDinner\n1\n1\n7.25\n\n\n172\n7.25\n5.15\nMale\nYes\nSun\nDinner\n2\n1\n8.77\n\n\n149\n7.51\n2.00\nMale\nNo\nThur\nLunch\n2\n1\n7.56\n\n\n92\n5.75\n1.00\nFemale\nYes\nFri\nDinner\n2\n1\n8.58\n\n\n222\n8.58\n1.92\nMale\nYes\nFri\nLunch\n1\n2\n10.09\n\n\n\n\n\n\n\n\n\n#Equivalent of sum(total_bill) over(partition by day) as sum_bill_day\n#Equivalent of sum(tip) over(partition by day order by total_bill asc) as cum_tip_day\n#Equivalent of sum(tip) over(partition by day order by total_bill rows between 3 preceeding and current row) as rolling_3d_sum \n\n(df\n .assign(sum_bill_day=lambda x:x.groupby(['day'])['total_bill'].transform('sum'))\n .assign(cum_tip_day=lambda x:x.sort_values(['total_bill']).groupby(['day'])['tip'].cumsum())\n .assign(rolling_3d_sum=lambda x:x.sort_values(['total_bill']).groupby(['day'])['tip'].rolling(window=2,min_periods=1).sum().reset_index(drop=True, level=0))\n .query(\"day=='Sat'\")\n .sort_values(['total_bill'])\n .head()\n)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nsum_bill_day\ncum_tip_day\nrolling_3d_sum\n\n\n\n\n67\n3.07\n1.00\nFemale\nYes\nSat\nDinner\n1\n1778.4\n1.00\n1.00\n\n\n111\n7.25\n1.00\nFemale\nNo\nSat\nDinner\n1\n1778.4\n2.00\n2.00\n\n\n218\n7.74\n1.44\nMale\nYes\nSat\nDinner\n2\n1778.4\n3.44\n2.44\n\n\n30\n9.55\n1.45\nMale\nNo\nSat\nDinner\n2\n1778.4\n4.89\n2.89\n\n\n235\n10.07\n1.25\nMale\nNo\nSat\nDinner\n2\n1778.4\n6.14\n2.70"
  },
  {
    "objectID": "posts/post-with-code/index.html#conclusion",
    "href": "posts/post-with-code/index.html#conclusion",
    "title": "Pandas Mastery: SQL Operations Made Easy",
    "section": "Conclusion",
    "text": "Conclusion\nThis guide demonstrates how Pandas can effectively replicate key SQL operations. By mastering these techniques, analysts can seamlessly transition between SQL and Pandas, choosing the most appropriate tool for their specific data analysis needs."
  },
  {
    "objectID": "posts/post-decorators/index.html",
    "href": "posts/post-decorators/index.html",
    "title": "Decorators",
    "section": "",
    "text": "A decorator is a special kind of callable that wraps another function or class to modify or enhance its behavior. They are used to apply repetitive operations or modifications across multiple functions or classes. You can introduce new behavior to functions or classes in several moments:\n\nAt the time of their definition.\n\nJust before they are called.\n\nRight after they are called.\n\nTo illustrate how decorators works, consider the following example: we’ve have created a decorator named dec, a type of function that takes another function - let’s say hello - as it parameter and that prints the name of the function. When you prepend hello with @dec, it effectively performs the operation dec(hello) behind the scenes.\n① - Prints the function name when the function is defined. Note the function is not called yet.\n\ndef dec(func): \n    print(f\"Function: {func.__name__} is defined\") #① \n\n@dec\ndef hello():\n    print(\"hello\")\n\nFunction: hello is defined\n\n\n\n\n\nLet’s extent the decorator from previous section to add the following additional behavior when the function is called.\n① - Print start prior to calling the function\n② - Call the actual function\n③ - Print end after calling the function\n\ndef dec(func): \n    print(f\"Function: {func.__name__} is defined\")\n    def wrapper():\n        print(\"start\") #①\n        func() #② \n        print(\"end\")#③\n    return wrapper\n\n@dec\ndef hello():\n    print(\"hello\")\nprint('-' * 40)\n\nhello()\n\nFunction: hello is defined\n----------------------------------------\nstart\nhello\nend\n\n\n\n\n\n① - Pass arguments in the function\n② - Add args and kwargs in the wrapper function arguments\n③ - Call the function with the args and kwargs passed\n\ndef dec(func): \n    print(f\"Function: {func.__name__} is defined\")\n    def wrapper(*args,**kwargs): #②\n        print(\"start\") \n        func(*args,**kwargs) #③ \n        print(\"end\")\n    return wrapper\n\n@dec\ndef hello(x:str)-&gt;None:#①\n    \"\"\"concat hello with passed in string and print\"\"\"\n    print(f\"hello {x}\")\n\nhello('world')\n\nprint('-' * 40)\n\n#④\nprint(f\"Func. Name: {hello.__name__}\",sep='\\n')\nprint(f\"Docstring: {hello.__doc__}\",sep='\\n')\nprint(f\"Annotations: {hello.__annotations__}\",sep='\\n')\n\nFunction: hello is defined\nstart\nhello world\nend\n----------------------------------------\nFunc. Name: wrapper\nDocstring: None\nAnnotations: {}\n\n\n\n\n\nWhen we use a decorator, the function dec is replaced by the wrapper function. This means we loose most of the properties like name, docstring, annotations, etc. We can use functools.wraps, which takes a function used in a decorator and add the functionality of copying over the function names, docstrings, annotation, etc.\n\nprint(f\"Func. Name: {hello.__name__}\",sep='\\n')\nprint(f\"Docstring: {hello.__doc__}\",sep='\\n')\nprint(f\"Annotations: {hello.__annotations__}\",sep='\\n')\n\nFunc. Name: wrapper\nDocstring: None\nAnnotations: {}\n\n\n\nfrom functools import wraps \n\ndef dec(func): \n    print(f\"Function: {func.__name__} is defined\")\n    @wraps(func)\n    def wrapper(*args,**kwargs): #②\n        print(\"start\") \n        func(*args,**kwargs) #③ \n        print(\"end\")\n    return wrapper\n\n@dec\ndef hello(x:str)-&gt;None: #①\n    \"\"\"concat hello with passed in string and print\"\"\"\n    print(f\"hello {x}\")\n\nhello('world')\n\n#④\nprint(f\"Func. Name: {hello.__name__}\",sep='\\n')\nprint(f\"Docstring: {hello.__doc__}\",sep='\\n')\nprint(f\"Annotations: {hello.__annotations__}\",sep='\\n')\n\nFunction: hello is defined\nstart\nhello world\nend\nFunc. Name: hello\nDocstring: concat hello with passed in string and print\nAnnotations: {'x': &lt;class 'str'&gt;, 'return': None}\n\n\nReturning value from a decorated function\n\nfrom functools import wraps \n\ndef dec(func): \n    print(f\"Function: {func.__name__} is defined\")\n    @wraps(func)\n    def wrapper(*args,**kwargs): #②\n        print(\"start\") \n        result=func(*args,**kwargs) #①\n        print(\"end\")\n        return result #②\n    return wrapper\n\n@dec\ndef hello(x:str)-&gt;None: \n    \"\"\"concat hello with passed in string and print\"\"\"\n    print(f\"hello {x}\")\n    return 'hello'\n\nhello('world')\n\nFunction: hello is defined\nstart\nhello world\nend\n\n\n'hello'\n\n\nPassing value to a decorator function\n\nfrom functools import wraps \n\ndef dec(a,b): \n    def dec_decorator(func):\n        print(f\"Function: {func.__name__} is defined\")\n        @wraps(func)\n        def wrapper(*args,**kwargs): #②\n            print(f\"start:{a}\") \n            result=func(*args,**kwargs) #①\n            print(f\"end:{b}\")\n            return result #②\n        return wrapper\n    return dec_decorator\n\n@dec('a','b')\ndef hello(x:str)-&gt;None: \n    \"\"\"concat hello with passed in string and print\"\"\"\n    print(f\"hello {x}\")\n    return 'hello'\n\nhello('world')\n\nFunction: hello is defined\nstart:a\nhello world\nend:b\n\n\n'hello'\n\n\nExample of a decorator\n\nfrom functools import wraps\nfrom time import perf_counter\ndef timer(func):\n    @wraps(func)\n    def wrapper(*args,**kwargs):\n        start_time=perf_counter()\n        func(*args,**kwargs)\n        end_time=perf_counter()\n        print(f\"\\N{Greek Capital Letter Delta} {end_time-start_time:.4f} sec\")\n    return wrapper\n\n@timer\ndef process_list(n=10000):\n    return sum(range(n))\n\nprocess_list()\n\nΔ 0.0002 sec"
  },
  {
    "objectID": "posts/post-decorators/index.html#decorator",
    "href": "posts/post-decorators/index.html#decorator",
    "title": "Decorators",
    "section": "",
    "text": "A decorator is a special kind of callable that wraps another function or class to modify or enhance its behavior. They are used to apply repetitive operations or modifications across multiple functions or classes. You can introduce new behavior to functions or classes in several moments:\n\nAt the time of their definition.\n\nJust before they are called.\n\nRight after they are called.\n\nTo illustrate how decorators works, consider the following example: we’ve have created a decorator named dec, a type of function that takes another function - let’s say hello - as it parameter and that prints the name of the function. When you prepend hello with @dec, it effectively performs the operation dec(hello) behind the scenes.\n① - Prints the function name when the function is defined. Note the function is not called yet.\n\ndef dec(func): \n    print(f\"Function: {func.__name__} is defined\") #① \n\n@dec\ndef hello():\n    print(\"hello\")\n\nFunction: hello is defined\n\n\n\n\n\nLet’s extent the decorator from previous section to add the following additional behavior when the function is called.\n① - Print start prior to calling the function\n② - Call the actual function\n③ - Print end after calling the function\n\ndef dec(func): \n    print(f\"Function: {func.__name__} is defined\")\n    def wrapper():\n        print(\"start\") #①\n        func() #② \n        print(\"end\")#③\n    return wrapper\n\n@dec\ndef hello():\n    print(\"hello\")\nprint('-' * 40)\n\nhello()\n\nFunction: hello is defined\n----------------------------------------\nstart\nhello\nend\n\n\n\n\n\n① - Pass arguments in the function\n② - Add args and kwargs in the wrapper function arguments\n③ - Call the function with the args and kwargs passed\n\ndef dec(func): \n    print(f\"Function: {func.__name__} is defined\")\n    def wrapper(*args,**kwargs): #②\n        print(\"start\") \n        func(*args,**kwargs) #③ \n        print(\"end\")\n    return wrapper\n\n@dec\ndef hello(x:str)-&gt;None:#①\n    \"\"\"concat hello with passed in string and print\"\"\"\n    print(f\"hello {x}\")\n\nhello('world')\n\nprint('-' * 40)\n\n#④\nprint(f\"Func. Name: {hello.__name__}\",sep='\\n')\nprint(f\"Docstring: {hello.__doc__}\",sep='\\n')\nprint(f\"Annotations: {hello.__annotations__}\",sep='\\n')\n\nFunction: hello is defined\nstart\nhello world\nend\n----------------------------------------\nFunc. Name: wrapper\nDocstring: None\nAnnotations: {}\n\n\n\n\n\nWhen we use a decorator, the function dec is replaced by the wrapper function. This means we loose most of the properties like name, docstring, annotations, etc. We can use functools.wraps, which takes a function used in a decorator and add the functionality of copying over the function names, docstrings, annotation, etc.\n\nprint(f\"Func. Name: {hello.__name__}\",sep='\\n')\nprint(f\"Docstring: {hello.__doc__}\",sep='\\n')\nprint(f\"Annotations: {hello.__annotations__}\",sep='\\n')\n\nFunc. Name: wrapper\nDocstring: None\nAnnotations: {}\n\n\n\nfrom functools import wraps \n\ndef dec(func): \n    print(f\"Function: {func.__name__} is defined\")\n    @wraps(func)\n    def wrapper(*args,**kwargs): #②\n        print(\"start\") \n        func(*args,**kwargs) #③ \n        print(\"end\")\n    return wrapper\n\n@dec\ndef hello(x:str)-&gt;None: #①\n    \"\"\"concat hello with passed in string and print\"\"\"\n    print(f\"hello {x}\")\n\nhello('world')\n\n#④\nprint(f\"Func. Name: {hello.__name__}\",sep='\\n')\nprint(f\"Docstring: {hello.__doc__}\",sep='\\n')\nprint(f\"Annotations: {hello.__annotations__}\",sep='\\n')\n\nFunction: hello is defined\nstart\nhello world\nend\nFunc. Name: hello\nDocstring: concat hello with passed in string and print\nAnnotations: {'x': &lt;class 'str'&gt;, 'return': None}\n\n\nReturning value from a decorated function\n\nfrom functools import wraps \n\ndef dec(func): \n    print(f\"Function: {func.__name__} is defined\")\n    @wraps(func)\n    def wrapper(*args,**kwargs): #②\n        print(\"start\") \n        result=func(*args,**kwargs) #①\n        print(\"end\")\n        return result #②\n    return wrapper\n\n@dec\ndef hello(x:str)-&gt;None: \n    \"\"\"concat hello with passed in string and print\"\"\"\n    print(f\"hello {x}\")\n    return 'hello'\n\nhello('world')\n\nFunction: hello is defined\nstart\nhello world\nend\n\n\n'hello'\n\n\nPassing value to a decorator function\n\nfrom functools import wraps \n\ndef dec(a,b): \n    def dec_decorator(func):\n        print(f\"Function: {func.__name__} is defined\")\n        @wraps(func)\n        def wrapper(*args,**kwargs): #②\n            print(f\"start:{a}\") \n            result=func(*args,**kwargs) #①\n            print(f\"end:{b}\")\n            return result #②\n        return wrapper\n    return dec_decorator\n\n@dec('a','b')\ndef hello(x:str)-&gt;None: \n    \"\"\"concat hello with passed in string and print\"\"\"\n    print(f\"hello {x}\")\n    return 'hello'\n\nhello('world')\n\nFunction: hello is defined\nstart:a\nhello world\nend:b\n\n\n'hello'\n\n\nExample of a decorator\n\nfrom functools import wraps\nfrom time import perf_counter\ndef timer(func):\n    @wraps(func)\n    def wrapper(*args,**kwargs):\n        start_time=perf_counter()\n        func(*args,**kwargs)\n        end_time=perf_counter()\n        print(f\"\\N{Greek Capital Letter Delta} {end_time-start_time:.4f} sec\")\n    return wrapper\n\n@timer\ndef process_list(n=10000):\n    return sum(range(n))\n\nprocess_list()\n\nΔ 0.0002 sec"
  },
  {
    "objectID": "posts/post-its/index.html",
    "href": "posts/post-its/index.html",
    "title": "Decorators",
    "section": "",
    "text": "This article is part of the “Day in life of a Data Scientist” series, sharing some of the real-world problems data scientist work on daily. The question: How do we measure the impact of launching of a machine learning the business metrics when A/B testing can’t be done due to operational constraints ?\nProblem:\nWe have developed an algorithm that helps agents perform outreach to maximize sales. Ideally, We would measure its impact using an A/B test, comparing the sales between agents using the model and those who aren’t. However, the operatinal challenges made running a A/B testing impractical.\nSolution:\nThe solution to this problem is to use Interrupted Time Series (ITS) analysis."
  },
  {
    "objectID": "posts/post-with-code/index.html#selecting-columns",
    "href": "posts/post-with-code/index.html#selecting-columns",
    "title": "Pandas Mastery: SQL Operations Made Easy",
    "section": "Selecting columns",
    "text": "Selecting columns\nIn Pandas, column selection is straightforward using the .loc accessor:\n\n(df\n .loc[:,['tip','sex']] # ①\n .head() \n)\n\n\n\n\n\n\n\n\n\ntip\nsex\n\n\n\n\n0\n1.01\nFemale\n\n\n1\n1.66\nMale\n\n\n2\n3.50\nMale\n\n\n3\n3.31\nMale\n\n\n4\n3.61\nFemale\n\n\n\n\n\n\n\n\nFor more dynamic selection, we can use list comprehensions:\n\n(df\n .loc[:,[col for col in df.columns if col.startswith('t')]] # ②\n .head() \n)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\ntime\n\n\n\n\n0\n16.99\n1.01\nDinner\n\n\n1\n10.34\n1.66\nDinner\n\n\n2\n21.01\n3.50\nDinner\n\n\n3\n23.68\n3.31\nDinner\n\n\n4\n24.59\n3.61\nDinner\n\n\n\n\n\n\n\n\nIn the code above, ① demonstrates basic column selection, while ② shows a more advanced technique using a list comprehension. This method ② is particularly useful when you need to select columns based on a specific condition, such as all columns starting with a certain letter."
  },
  {
    "objectID": "posts/post-with-code/index.html#column-manipulation",
    "href": "posts/post-with-code/index.html#column-manipulation",
    "title": "Pandas Mastery: SQL Operations Made Easy",
    "section": "Column Manipulation",
    "text": "Column Manipulation\nUse the .assign method to create or modify columns:\n\n(df\n .loc[:, ['total_bill', 'tip', 'sex', 'day', 'time']]\n .assign(percentage_tip=lambda x: x['tip'] / x['total_bill'])  # ①\n .assign(tip=lambda x: x['tip'] + 1)  # ②\n .assign(count=1)  # ③\n .head()\n)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nday\ntime\npercentage_tip\ncount\n\n\n\n\n0\n16.99\n2.01\nFemale\nSun\nDinner\n0.059447\n1\n\n\n1\n10.34\n2.66\nMale\nSun\nDinner\n0.160542\n1\n\n\n2\n21.01\n4.50\nMale\nSun\nDinner\n0.166587\n1\n\n\n3\n23.68\n4.31\nMale\nSun\nDinner\n0.139780\n1\n\n\n4\n24.59\n4.61\nFemale\nSun\nDinner\n0.146808\n1\n\n\n\n\n\n\n\n\nHere, ① calculates a new column, ② modifies an existing column, and ③ adds a constant value column. This demonstrates the versatility of assign() in performing various column operations in a single chain."
  },
  {
    "objectID": "posts/post-with-code/index.html#filtering-rows",
    "href": "posts/post-with-code/index.html#filtering-rows",
    "title": "Pandas Mastery: SQL Operations Made Easy",
    "section": "Filtering Rows",
    "text": "Filtering Rows\nUse the .loc method to filter rows:\n\n#Filter only transaction with more than 15% in tips\n(df\n .loc[:,['total_bill','tip','sex','day','time']]\n .assign(percentage_tip=lambda x:x['tip']/x['total_bill'])\n .loc[lambda x:x['percentage_tip']&gt;.15,:] # ①\n .head()\n)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nday\ntime\npercentage_tip\n\n\n\n\n1\n10.34\n1.66\nMale\nSun\nDinner\n0.160542\n\n\n2\n21.01\n3.50\nMale\nSun\nDinner\n0.166587\n\n\n5\n25.29\n4.71\nMale\nSun\nDinner\n0.186240\n\n\n6\n8.77\n2.00\nMale\nSun\nDinner\n0.228050\n\n\n9\n14.78\n3.23\nMale\nSun\nDinner\n0.218539\n\n\n\n\n\n\n\n\nThe filter condition ① uses a lambda function within .loc[] to select rows where the tip percentage exceeds 15%. This approach provides a clean, SQL-like syntax for row filtering.\n\n#Filter only transactions happend on Sunday and Monday\n(df\n .loc[:,['total_bill','tip','sex','day','time']]\n .loc[lambda x:x['day'].isin(['Sun','Mon']),:]\n .head()\n)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nday\ntime\n\n\n\n\n0\n16.99\n1.01\nFemale\nSun\nDinner\n\n\n1\n10.34\n1.66\nMale\nSun\nDinner\n\n\n2\n21.01\n3.50\nMale\nSun\nDinner\n\n\n3\n23.68\n3.31\nMale\nSun\nDinner\n\n\n4\n24.59\n3.61\nFemale\nSun\nDinner"
  },
  {
    "objectID": "posts/post-with-code/index.html#window-functions",
    "href": "posts/post-with-code/index.html#window-functions",
    "title": "Pandas Mastery: SQL Operations Made Easy",
    "section": "Window Functions",
    "text": "Window Functions\nPandas can replicate complex SQL window functions:\n\n\n\n\n\n\nNote\n\n\n\nWindow functions in Pandas, while powerful, can be complex. They offer advanced data manipulation capabilities similar to those in SQL.\n\n\n\n(df\n .assign(row_number=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day']).cumcount()+1)  # ①\n .assign(prev_bill=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day'])['total_bill'].shift(1)) # ②\n .assign(next_bill=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day'])['total_bill'].shift(-1)) # \n .sort_values(['row_number'])\n .head()\n)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nrow_number\nprev_bill\nnext_bill\n\n\n\n\n67\n3.07\n1.00\nFemale\nYes\nSat\nDinner\n1\n1\nNaN\n7.25\n\n\n172\n7.25\n5.15\nMale\nYes\nSun\nDinner\n2\n1\nNaN\n8.77\n\n\n149\n7.51\n2.00\nMale\nNo\nThur\nLunch\n2\n1\nNaN\n7.56\n\n\n92\n5.75\n1.00\nFemale\nYes\nFri\nDinner\n2\n1\nNaN\n8.58\n\n\n222\n8.58\n1.92\nMale\nYes\nFri\nLunch\n1\n2\n5.75\n10.09\n\n\n\n\n\n\n\n\nHere, ① creates a row number within each day group, sorted by total bill, similar to SQL’s ROW_NUMBER() function. ② calculates the previous bill amount within each day group, mimicking SQL’s LAG() function. ③ computes the next bill amount within each day group, equivalent to SQL’s LEAD() function.\n\n(df\n .assign(sum_bill_day=lambda x:x.groupby(['day'])['total_bill'].transform('sum')) # ④\n .assign(cum_tip_day=lambda x:x.sort_values(['total_bill']).groupby(['day'])['tip'].cumsum()) # ⑤\n .assign(rolling_3d_sum=lambda x:x.sort_values(['total_bill']).groupby(['day'])['tip'].rolling(window=2,min_periods=1).sum().reset_index(drop=True, level=0)) # ⑥\n .query(\"day=='Sat'\")\n .sort_values(['total_bill'])\n .head()\n)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nsum_bill_day\ncum_tip_day\nrolling_3d_sum\n\n\n\n\n67\n3.07\n1.00\nFemale\nYes\nSat\nDinner\n1\n1778.4\n1.00\n1.00\n\n\n111\n7.25\n1.00\nFemale\nNo\nSat\nDinner\n1\n1778.4\n2.00\n2.00\n\n\n218\n7.74\n1.44\nMale\nYes\nSat\nDinner\n2\n1778.4\n3.44\n2.44\n\n\n30\n9.55\n1.45\nMale\nNo\nSat\nDinner\n2\n1778.4\n4.89\n2.89\n\n\n235\n10.07\n1.25\nMale\nNo\nSat\nDinner\n2\n1778.4\n6.14\n2.70\n\n\n\n\n\n\n\n\n④ Calculates the sum of total bills for each day, equivalent to SUM(total_bill) OVER (PARTITION BY day) in SQL. ⑤ Computes the cumulative sum of tips within each day, ordered by total bill. This is similar to SUM(tip) OVER (PARTITION BY day ORDER BY total_bill ASC) in SQL. ⑥ Performs a rolling sum of tips over a 2-row window (current row and 1 preceding) within each day, ordered by total bill. This complex operation is akin to SUM(tip) OVER (PARTITION BY day ORDER BY total_bill ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) in SQL."
  },
  {
    "objectID": "posts/post-with-code/index.html#introduction",
    "href": "posts/post-with-code/index.html#introduction",
    "title": "Pandas Mastery: SQL Operations Made Easy",
    "section": "",
    "text": "Data analysis often involves working with structured datasets organized in rows and columns. While SQL has long been the go-to language for manipulating such data, Python’s Pandas library offers comparable functionality with added flexibility. This post explores how to perform essential SQL-like operations in Pandas, providing a bridge for analysts transitioning between these two powerful tools."
  },
  {
    "objectID": "posts/post-with-code/index.html#setting-up-the-environment",
    "href": "posts/post-with-code/index.html#setting-up-the-environment",
    "title": "Pandas Mastery: SQL Operations Made Easy",
    "section": "Setting Up the Environment",
    "text": "Setting Up the Environment\nLet’s begin by importing the necessary libraries and loading our dataset:\n\nimport pandas as pd\nimport numpy as np\npd.options.display.max_rows = 20\ndf = pd.read_csv(\"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv\")\ndf.head(5)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4"
  },
  {
    "objectID": "posts/post-with-code/index.html#grouping-and-aggregation",
    "href": "posts/post-with-code/index.html#grouping-and-aggregation",
    "title": "Pandas Mastery: SQL Operations Made Easy",
    "section": "Grouping and Aggregation",
    "text": "Grouping and Aggregation\nPandas offers powerful grouping and aggregation capabilities:\n\n(df\n .groupby(['day'])  # ①\n .agg(avg_bill=('total_bill', 'mean'),  # ②\n      total_bill=('total_bill', 'sum'))\n .reset_index()\n)\n\n\n\n\n\n\n\n\n\nday\navg_bill\ntotal_bill\n\n\n\n\n0\nFri\n17.151579\n325.88\n\n\n1\nSat\n20.441379\n1778.40\n\n\n2\nSun\n21.410000\n1627.16\n\n\n3\nThur\n17.682742\n1096.33\n\n\n\n\n\n\n\n\nIn this example, ① groups the data by the ‘day’ column, and ② applies multiple aggregations. The agg() method allows for clear specification of column names and aggregation functions, similar to SQL’s GROUP BY and aggregate functions.\n\n#By day get average of total bill using : functions, lambda functions, numpy functions \n(df\n .groupby(['day'])\n .agg(avg_bill_mean=('total_bill','mean')\n     ,avg_bill_lambda=('total_bill',lambda x:x.mean()) #using lambda functions\n     ,avg_bill_np=('total_bill',np.mean)) #using numpy functions \n .reset_index()\n)\n\n/var/folders/_m/75zm23zj7ps40gd_wwbvgfxh0000gn/T/ipykernel_25443/586994573.py:2: FutureWarning:\n\nThe provided callable &lt;function mean at 0x7fdaf02f8ca0&gt; is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n\n\n\n\n\n\n\n\n\n\n\nday\navg_bill_mean\navg_bill_lambda\navg_bill_np\n\n\n\n\n0\nFri\n17.151579\n17.151579\n17.151579\n\n\n1\nSat\n20.441379\n20.441379\n20.441379\n\n\n2\nSun\n21.410000\n21.410000\n21.410000\n\n\n3\nThur\n17.682742\n17.682742\n17.682742"
  }
]