[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Mastering Data Manipulation in Pandas: A Guide to Key SQL Operations",
    "section": "",
    "text": "Data is often organized in a rectangular format with rows and columns, commonly known as table data, data frames, structured data, or spreadsheets. In Python, the Pandas library is a powerful tool for manipulating such structured datasets. This blog post explores essential operations in data analysis with Pandas, aligning with SQL concepts such as selecting columns, applying conditions, grouping, aggregating, ordering, and joining datasets.\nHaving worked with Pandas, I noticed that while it offers numerous methods for similar tasks, the transition from SQL to Pandas can sometimes lead to less elegant and harder-to-debug code. This post aims to simplify the execution of these core SQL operations in Pandas, providing clear examples to enhance your data manipulation skills in Python.\n\nimport pandas as pd\nimport numpy as np\ndf = pd.read_csv(\"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv\")\npd.options.display.max_rows = 20\ndf.head(5)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dataflake",
    "section": "",
    "text": "Mastering Data Manipulation in Pandas: A Guide to Key SQL Operations\n\n\n\n\n\n\npandas\n\n\nsql\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nMar 2, 2024\n\n\nNaveenan Arjunan\n\n\n\n\n\n\n\n\n\n\n\n\nDecorators\n\n\n\n\n\n\npython\n\n\nadvanced-python\n\n\n\n\n\n\n\n\n\nMar 2, 2024\n\n\nNaveenan Arjunan\n\n\n\n\n\n\n\n\n\n\n\n\nDecorators\n\n\n\n\n\n\npython\n\n\nA/B testing\n\n\ndatascience\n\n\n\n\n\n\n\n\n\nMar 2, 2024\n\n\nNaveenan Arjunan\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nFeb 28, 2024\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html#about",
    "href": "posts/post-with-code/index.html#about",
    "title": "Mastering Data Manipulation in Pandas: A Guide to Key SQL Operations",
    "section": "",
    "text": "Data is often organized in a rectangular format with rows and columns, commonly known as table data, data frames, structured data, or spreadsheets. In Python, the Pandas library is a powerful tool for manipulating such structured datasets. This blog post explores essential operations in data analysis with Pandas, aligning with SQL concepts such as selecting columns, applying conditions, grouping, aggregating, ordering, and joining datasets.\nHaving worked with Pandas, I noticed that while it offers numerous methods for similar tasks, the transition from SQL to Pandas can sometimes lead to less elegant and harder-to-debug code. This post aims to simplify the execution of these core SQL operations in Pandas, providing clear examples to enhance your data manipulation skills in Python.\n\nimport pandas as pd\nimport numpy as np\ndf = pd.read_csv(\"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv\")\npd.options.display.max_rows = 20\ndf.head(5)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4"
  },
  {
    "objectID": "posts/post-with-code/index.html#data-preparation",
    "href": "posts/post-with-code/index.html#data-preparation",
    "title": "Audience Splitting in A/B Experiments",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nLets create a spark session connected to local server.\nLets create a dummy dataset with 100,000 customers along with gender information.\nAdd uuid column to the dataframe to uniquely identify a user.\nConvert pandas dataframe to a spark dataframe\nRegister the spark dataframe as “user_table” to be accessed in Hive\n\n\nprint (\"hello world\")\n\nhello world"
  },
  {
    "objectID": "posts/post-with-code/index.html#select-columns",
    "href": "posts/post-with-code/index.html#select-columns",
    "title": "The Pandas Reference",
    "section": "Select columns",
    "text": "Select columns\nTo select specific columns, employ the .loc method combined with a list of the column names you wish to include. I suggest adopting this approach because it grants enhanced flexibility for your data analysis endeavors.\n.loc[:,['col1','col2']]\nFor example, to extract the total_bill and tips columns from your dataset, utilize method chaining to execute these operations sequentially. This technique allows for a streamlined and efficient workflow.\n\n(df\n .loc[:,['tip','sex']]\n .head()\n)\n\n\n\n\n\n\n\n\n\ntip\nsex\n\n\n\n\n0\n1.01\nFemale\n\n\n1\n1.66\nMale\n\n\n2\n3.50\nMale\n\n\n3\n3.31\nMale\n\n\n4\n3.61\nFemale\n\n\n\n\n\n\n\n\nSelect columns that begin with the letter ‘t’ by employing a straightforward and intelligible syntax. This method simplifies executing complex selection tasks in Pandas, making your data analysis more efficient.\n\n(df\n .loc[:,[col for col in df.columns if col.startswith('t')]]\n .head()\n)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\ntime\n\n\n\n\n0\n16.99\n1.01\nDinner\n\n\n1\n10.34\n1.66\nDinner\n\n\n2\n21.01\n3.50\nDinner\n\n\n3\n23.68\n3.31\nDinner\n\n\n4\n24.59\n3.61\nDinner"
  },
  {
    "objectID": "posts/post-with-code/index.html#select-columns-manipulation",
    "href": "posts/post-with-code/index.html#select-columns-manipulation",
    "title": "The Pandas Reference",
    "section": "Select columns manipulation",
    "text": "Select columns manipulation\nTo create new columns or modify existing ones, the .assign method is your go-to. This approach not only allows for the addition of new columns but also the updating of existing ones in a concise manner.\nTo add a new column with a constant value .assign(new_col=1) To introduce a new column based on operations with existing columns: .assign(new_col=lambda x:x['col']+1) To update an existing column by modifying its values: .assign(old_col=lambda x:x['old_col']+1)\n\n(df\n .loc[:,['total_bill','tip','sex','day','time']]\n .assign(percentage_tip=lambda x:x['tip']/x['total_bill']) #add new column\n .assign(tip=lambda x:x['tip']+1) # update existing column \n .assign(count=1) #add constant value \n .head()\n)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nday\ntime\npercentage_tip\ncount\n\n\n\n\n0\n16.99\n2.01\nFemale\nSun\nDinner\n0.059447\n1\n\n\n1\n10.34\n2.66\nMale\nSun\nDinner\n0.160542\n1\n\n\n2\n21.01\n4.50\nMale\nSun\nDinner\n0.166587\n1\n\n\n3\n23.68\n4.31\nMale\nSun\nDinner\n0.139780\n1\n\n\n4\n24.59\n4.61\nFemale\nSun\nDinner\n0.146808\n1"
  },
  {
    "objectID": "posts/post-with-code/index.html#filter-rows-where",
    "href": "posts/post-with-code/index.html#filter-rows-where",
    "title": "The Pandas Reference",
    "section": "Filter rows (where)",
    "text": "Filter rows (where)\nUtilize the query method to filter row in a pandas Dataframe\nval=10 .query(\"col1&gt;='10'\") .query(\"col1&gt;='@val'\") .query(f\"col1&gt;='{val}'\") .query(\"col1.isin(['a','b'])\",engine='python')\n\n#filter only transaction with more than 15% in tips\n(df\n .loc[:,['total_bill','tip','sex','day','time']]\n .assign(percentage_tip=lambda x:x['tip']/x['total_bill'])\n .query(\"percentage_tip&gt;.15\")\n .head()\n)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nday\ntime\npercentage_tip\n\n\n\n\n1\n10.34\n1.66\nMale\nSun\nDinner\n0.160542\n\n\n2\n21.01\n3.50\nMale\nSun\nDinner\n0.166587\n\n\n5\n25.29\n4.71\nMale\nSun\nDinner\n0.186240\n\n\n6\n8.77\n2.00\nMale\nSun\nDinner\n0.228050\n\n\n9\n14.78\n3.23\nMale\nSun\nDinner\n0.218539\n\n\n\n\n\n\n\n\n\nper_tip=.15\n#using @ within query to refer a variable in the filter \nprint(\"\")\ndisplay(df\n .loc[:,['total_bill','tip','sex','day','time']]\n .assign(percentage_tip=lambda x:x['tip']/x['total_bill'])\n .query(\"percentage_tip&gt;@per_tip\")\n .head()\n)\n\n#using f-string to perform filtering\ndisplay(df\n .loc[:,['total_bill','tip','sex','day','time']]\n .assign(percentage_tip=lambda x:x['tip']/x['total_bill'])\n .query(f\"percentage_tip&gt;{per_tip}\")\n .head()\n)\n\n\n\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nday\ntime\npercentage_tip\n\n\n\n\n1\n10.34\n1.66\nMale\nSun\nDinner\n0.160542\n\n\n2\n21.01\n3.50\nMale\nSun\nDinner\n0.166587\n\n\n5\n25.29\n4.71\nMale\nSun\nDinner\n0.186240\n\n\n6\n8.77\n2.00\nMale\nSun\nDinner\n0.228050\n\n\n9\n14.78\n3.23\nMale\nSun\nDinner\n0.218539\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nday\ntime\npercentage_tip\n\n\n\n\n1\n10.34\n1.66\nMale\nSun\nDinner\n0.160542\n\n\n2\n21.01\n3.50\nMale\nSun\nDinner\n0.166587\n\n\n5\n25.29\n4.71\nMale\nSun\nDinner\n0.186240\n\n\n6\n8.77\n2.00\nMale\nSun\nDinner\n0.228050\n\n\n9\n14.78\n3.23\nMale\nSun\nDinner\n0.218539\n\n\n\n\n\n\n\n\n\n#Filter only transactions happend on Sunday and Monday\n(df\n .loc[:,['total_bill','tip','sex','day','time']]\n .query(\"day.isin(['Sun','Mon'])\",engine='python')\n .head()\n)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nday\ntime\n\n\n\n\n0\n16.99\n1.01\nFemale\nSun\nDinner\n\n\n1\n10.34\n1.66\nMale\nSun\nDinner\n\n\n2\n21.01\n3.50\nMale\nSun\nDinner\n\n\n3\n23.68\n3.31\nMale\nSun\nDinner\n\n\n4\n24.59\n3.61\nFemale\nSun\nDinner"
  },
  {
    "objectID": "posts/post-with-code/index.html#group-by-and-aggregation",
    "href": "posts/post-with-code/index.html#group-by-and-aggregation",
    "title": "Mastering Data Manipulation in Pandas: A Guide to Key SQL Operations",
    "section": "Group By and Aggregation",
    "text": "Group By and Aggregation\nUse groupby and agg for aggregations:\n\n#By day get average and total bill\n(df\n .groupby(['day'])\n .agg(avg_bill=('total_bill','mean')\n     ,total_bill=('total_bill','sum')) #multiple column aggregations supported\n .reset_index()\n)\n\n\n\n\n\n\n\n\n\nday\navg_bill\ntotal_bill\n\n\n\n\n0\nFri\n17.151579\n325.88\n\n\n1\nSat\n20.441379\n1778.40\n\n\n2\nSun\n21.410000\n1627.16\n\n\n3\nThur\n17.682742\n1096.33\n\n\n\n\n\n\n\n\n\n#By day get average of total bill using : functions, lambda functions, numpy functions \n(df\n .groupby(['day'])\n .agg(avg_bill_mean=('total_bill','mean')\n     ,avg_bill_lambda=('total_bill',lambda x:x.mean()) #using lambda functions\n     ,avg_bill_np=('total_bill',np.mean)) #using numpy functions \n .reset_index()\n)\n\n/var/folders/_m/75zm23zj7ps40gd_wwbvgfxh0000gn/T/ipykernel_60230/586994573.py:2: FutureWarning:\n\nThe provided callable &lt;function mean at 0x7fb018630ca0&gt; is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n\n\n\n\n\n\n\n\n\n\n\nday\navg_bill_mean\navg_bill_lambda\navg_bill_np\n\n\n\n\n0\nFri\n17.151579\n17.151579\n17.151579\n\n\n1\nSat\n20.441379\n20.441379\n20.441379\n\n\n2\nSun\n21.410000\n21.410000\n21.410000\n\n\n3\nThur\n17.682742\n17.682742\n17.682742"
  },
  {
    "objectID": "posts/post-with-code/index.html#ordering-rows",
    "href": "posts/post-with-code/index.html#ordering-rows",
    "title": "Mastering Data Manipulation in Pandas: A Guide to Key SQL Operations",
    "section": "Ordering Rows",
    "text": "Ordering Rows\nSort data using .sort_values:\n\n#By day get average and total bill.Sort the output by total_bill\n(df\n .groupby(['day'])\n .agg(avg_bill=('total_bill','mean')\n     ,total_bill=('total_bill','sum'))\n .reset_index()\n .sort_values(['total_bill'],ascending=False) #Default in ascending \n)\n\n\n\n\n\n\n\n\n\nday\navg_bill\ntotal_bill\n\n\n\n\n1\nSat\n20.441379\n1778.40\n\n\n2\nSun\n21.410000\n1627.16\n\n\n3\nThur\n17.682742\n1096.33\n\n\n0\nFri\n17.151579\n325.88\n\n\n\n\n\n\n\n\n\n#By day get average and total bill.Sort the output by total_bill and avg_bill\n(df\n .groupby(['day'])\n .agg(avg_bill=('total_bill','mean')\n     ,total_bill=('total_bill','sum'))\n .reset_index()\n .sort_values(['total_bill','avg_bill'],ascending=[False,True]) #By multiple columns one by asc and other by desc\n)\n\n\n\n\n\n\n\n\n\nday\navg_bill\ntotal_bill\n\n\n\n\n1\nSat\n20.441379\n1778.40\n\n\n2\nSun\n21.410000\n1627.16\n\n\n3\nThur\n17.682742\n1096.33\n\n\n0\nFri\n17.151579\n325.88"
  },
  {
    "objectID": "posts/post-with-code/index.html#window-function",
    "href": "posts/post-with-code/index.html#window-function",
    "title": "The Pandas Reference",
    "section": "Window function",
    "text": "Window function\nWindow functions in SQL offering advanced data manipulation capabilities. We will explore how to utilize key functions such as row_number(), LEAD()/LAG(), and calculate a running sum within each group (partition).\n\n#Equivalent of row_number() over(partition by day order by total_bill asc) as row_number\n(df\n .assign(row_number=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day']).cumcount()+1)\n .sort_values(['row_number'])\n .head()\n)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nrow_number\n\n\n\n\n67\n3.07\n1.00\nFemale\nYes\nSat\nDinner\n1\n1\n\n\n172\n7.25\n5.15\nMale\nYes\nSun\nDinner\n2\n1\n\n\n149\n7.51\n2.00\nMale\nNo\nThur\nLunch\n2\n1\n\n\n92\n5.75\n1.00\nFemale\nYes\nFri\nDinner\n2\n1\n\n\n222\n8.58\n1.92\nMale\nYes\nFri\nLunch\n1\n2\n\n\n\n\n\n\n\n\n\n#Equivalent of lag(total_bill) over(partition by day order by total_bill asc) as previous_bill\n(df\n .assign(row_number=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day']).cumcount()+1)\n .assign(prev_bill=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day'])['total_bill'].shift(1))\n .sort_values(['row_number'])\n .head()\n)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nrow_number\nprev_bill\n\n\n\n\n67\n3.07\n1.00\nFemale\nYes\nSat\nDinner\n1\n1\nNaN\n\n\n172\n7.25\n5.15\nMale\nYes\nSun\nDinner\n2\n1\nNaN\n\n\n149\n7.51\n2.00\nMale\nNo\nThur\nLunch\n2\n1\nNaN\n\n\n92\n5.75\n1.00\nFemale\nYes\nFri\nDinner\n2\n1\nNaN\n\n\n222\n8.58\n1.92\nMale\nYes\nFri\nLunch\n1\n2\n5.75\n\n\n\n\n\n\n\n\n\n#Equivalent of lead(total_bill) over(partition by day order by total_bill asc) as previous_bill\n(df\n .assign(row_number=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day']).cumcount()+1)\n .assign(next_bill=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day'])['total_bill'].shift(-1))\n .sort_values(['row_number'])\n .head()\n)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nrow_number\nnext_bill\n\n\n\n\n67\n3.07\n1.00\nFemale\nYes\nSat\nDinner\n1\n1\n7.25\n\n\n172\n7.25\n5.15\nMale\nYes\nSun\nDinner\n2\n1\n8.77\n\n\n149\n7.51\n2.00\nMale\nNo\nThur\nLunch\n2\n1\n7.56\n\n\n92\n5.75\n1.00\nFemale\nYes\nFri\nDinner\n2\n1\n8.58\n\n\n222\n8.58\n1.92\nMale\nYes\nFri\nLunch\n1\n2\n10.09\n\n\n\n\n\n\n\n\n\n#Equivalent of sum(total_bill) over(partition by day) as sum_bill_day\n#Equivalent of sum(tip) over(partition by day order by total_bill asc) as cum_tip_day\n#Equivalent of sum(tip) over(partition by day order by total_bill rows between 3 preceeding and current row) as rolling_3d_sum \n\n(df\n .assign(sum_bill_day=lambda x:x.groupby(['day'])['total_bill'].transform('sum'))\n .assign(cum_tip_day=lambda x:x.sort_values(['total_bill']).groupby(['day'])['tip'].cumsum())\n .assign(rolling_3d_sum=lambda x:x.sort_values(['total_bill']).groupby(['day'])['tip'].rolling(window=2,min_periods=1).sum().reset_index(drop=True, level=0))\n .query(\"day=='Sat'\")\n .sort_values(['total_bill'])\n .head()\n)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nsum_bill_day\ncum_tip_day\nrolling_3d_sum\n\n\n\n\n67\n3.07\n1.00\nFemale\nYes\nSat\nDinner\n1\n1778.4\n1.00\n1.00\n\n\n111\n7.25\n1.00\nFemale\nNo\nSat\nDinner\n1\n1778.4\n2.00\n2.00\n\n\n218\n7.74\n1.44\nMale\nYes\nSat\nDinner\n2\n1778.4\n3.44\n2.44\n\n\n30\n9.55\n1.45\nMale\nNo\nSat\nDinner\n2\n1778.4\n4.89\n2.89\n\n\n235\n10.07\n1.25\nMale\nNo\nSat\nDinner\n2\n1778.4\n6.14\n2.70"
  },
  {
    "objectID": "posts/post-with-code/index.html#conclusion",
    "href": "posts/post-with-code/index.html#conclusion",
    "title": "Mastering Data Manipulation in Pandas: A Guide to Key SQL Operations",
    "section": "Conclusion",
    "text": "Conclusion\nThis post provides fundamental strategies for effective data analysis with Pandas. Future updates will include additional examples to further simplify data analysis using Pandas."
  },
  {
    "objectID": "posts/post-decorators/index.html",
    "href": "posts/post-decorators/index.html",
    "title": "Decorators",
    "section": "",
    "text": "A decorator is a special kind of callable that wraps another function or class to modify or enhance its behavior. They are used to apply repetitive operations or modifications across multiple functions or classes. You can introduce new behavior to functions or classes in several moments:\n\nAt the time of their definition.\n\nJust before they are called.\n\nRight after they are called.\n\nTo illustrate how decorators works, consider the following example: we’ve have created a decorator named dec, a type of function that takes another function - let’s say hello - as it parameter and that prints the name of the function. When you prepend hello with @dec, it effectively performs the operation dec(hello) behind the scenes.\n① - Prints the function name when the function is defined. Note the function is not called yet.\n\ndef dec(func): \n    print(f\"Function: {func.__name__} is defined\") #① \n\n@dec\ndef hello():\n    print(\"hello\")\n\nFunction: hello is defined\n\n\n\n\n\nLet’s extent the decorator from previous section to add the following additional behavior when the function is called.\n① - Print start prior to calling the function\n② - Call the actual function\n③ - Print end after calling the function\n\ndef dec(func): \n    print(f\"Function: {func.__name__} is defined\")\n    def wrapper():\n        print(\"start\") #①\n        func() #② \n        print(\"end\")#③\n    return wrapper\n\n@dec\ndef hello():\n    print(\"hello\")\nprint('-' * 40)\n\nhello()\n\nFunction: hello is defined\n----------------------------------------\nstart\nhello\nend\n\n\n\n\n\n① - Pass arguments in the function\n② - Add args and kwargs in the wrapper function arguments\n③ - Call the function with the args and kwargs passed\n\ndef dec(func): \n    print(f\"Function: {func.__name__} is defined\")\n    def wrapper(*args,**kwargs): #②\n        print(\"start\") \n        func(*args,**kwargs) #③ \n        print(\"end\")\n    return wrapper\n\n@dec\ndef hello(x:str)-&gt;None:#①\n    \"\"\"concat hello with passed in string and print\"\"\"\n    print(f\"hello {x}\")\n\nhello('world')\n\nprint('-' * 40)\n\n#④\nprint(f\"Func. Name: {hello.__name__}\",sep='\\n')\nprint(f\"Docstring: {hello.__doc__}\",sep='\\n')\nprint(f\"Annotations: {hello.__annotations__}\",sep='\\n')\n\nFunction: hello is defined\nstart\nhello world\nend\n----------------------------------------\nFunc. Name: wrapper\nDocstring: None\nAnnotations: {}\n\n\n\n\n\nWhen we use a decorator, the function dec is replaced by the wrapper function. This means we loose most of the properties like name, docstring, annotations, etc. We can use functools.wraps, which takes a function used in a decorator and add the functionality of copying over the function names, docstrings, annotation, etc.\n\nprint(f\"Func. Name: {hello.__name__}\",sep='\\n')\nprint(f\"Docstring: {hello.__doc__}\",sep='\\n')\nprint(f\"Annotations: {hello.__annotations__}\",sep='\\n')\n\nFunc. Name: wrapper\nDocstring: None\nAnnotations: {}\n\n\n\nfrom functools import wraps \n\ndef dec(func): \n    print(f\"Function: {func.__name__} is defined\")\n    @wraps(func)\n    def wrapper(*args,**kwargs): #②\n        print(\"start\") \n        func(*args,**kwargs) #③ \n        print(\"end\")\n    return wrapper\n\n@dec\ndef hello(x:str)-&gt;None: #①\n    \"\"\"concat hello with passed in string and print\"\"\"\n    print(f\"hello {x}\")\n\nhello('world')\n\n#④\nprint(f\"Func. Name: {hello.__name__}\",sep='\\n')\nprint(f\"Docstring: {hello.__doc__}\",sep='\\n')\nprint(f\"Annotations: {hello.__annotations__}\",sep='\\n')\n\nFunction: hello is defined\nstart\nhello world\nend\nFunc. Name: hello\nDocstring: concat hello with passed in string and print\nAnnotations: {'x': &lt;class 'str'&gt;, 'return': None}\n\n\nReturning value from a decorated function\n\nfrom functools import wraps \n\ndef dec(func): \n    print(f\"Function: {func.__name__} is defined\")\n    @wraps(func)\n    def wrapper(*args,**kwargs): #②\n        print(\"start\") \n        result=func(*args,**kwargs) #①\n        print(\"end\")\n        return result #②\n    return wrapper\n\n@dec\ndef hello(x:str)-&gt;None: \n    \"\"\"concat hello with passed in string and print\"\"\"\n    print(f\"hello {x}\")\n    return 'hello'\n\nhello('world')\n\nFunction: hello is defined\nstart\nhello world\nend\n\n\n'hello'\n\n\nPassing value to a decorator function\n\nfrom functools import wraps \n\ndef dec(a,b): \n    def dec_decorator(func):\n        print(f\"Function: {func.__name__} is defined\")\n        @wraps(func)\n        def wrapper(*args,**kwargs): #②\n            print(f\"start:{a}\") \n            result=func(*args,**kwargs) #①\n            print(f\"end:{b}\")\n            return result #②\n        return wrapper\n    return dec_decorator\n\n@dec('a','b')\ndef hello(x:str)-&gt;None: \n    \"\"\"concat hello with passed in string and print\"\"\"\n    print(f\"hello {x}\")\n    return 'hello'\n\nhello('world')\n\nFunction: hello is defined\nstart:a\nhello world\nend:b\n\n\n'hello'\n\n\nExample of a decorator\n\nfrom functools import wraps\nfrom time import perf_counter\ndef timer(func):\n    @wraps(func)\n    def wrapper(*args,**kwargs):\n        start_time=perf_counter()\n        func(*args,**kwargs)\n        end_time=perf_counter()\n        print(f\"\\N{Greek Capital Letter Delta} {end_time-start_time:.4f} sec\")\n    return wrapper\n\n@timer\ndef process_list(n=10000):\n    return sum(range(n))\n\nprocess_list()\n\nΔ 0.0002 sec"
  },
  {
    "objectID": "posts/post-decorators/index.html#decorator",
    "href": "posts/post-decorators/index.html#decorator",
    "title": "Decorators",
    "section": "",
    "text": "A decorator is a special kind of callable that wraps another function or class to modify or enhance its behavior. They are used to apply repetitive operations or modifications across multiple functions or classes. You can introduce new behavior to functions or classes in several moments:\n\nAt the time of their definition.\n\nJust before they are called.\n\nRight after they are called.\n\nTo illustrate how decorators works, consider the following example: we’ve have created a decorator named dec, a type of function that takes another function - let’s say hello - as it parameter and that prints the name of the function. When you prepend hello with @dec, it effectively performs the operation dec(hello) behind the scenes.\n① - Prints the function name when the function is defined. Note the function is not called yet.\n\ndef dec(func): \n    print(f\"Function: {func.__name__} is defined\") #① \n\n@dec\ndef hello():\n    print(\"hello\")\n\nFunction: hello is defined\n\n\n\n\n\nLet’s extent the decorator from previous section to add the following additional behavior when the function is called.\n① - Print start prior to calling the function\n② - Call the actual function\n③ - Print end after calling the function\n\ndef dec(func): \n    print(f\"Function: {func.__name__} is defined\")\n    def wrapper():\n        print(\"start\") #①\n        func() #② \n        print(\"end\")#③\n    return wrapper\n\n@dec\ndef hello():\n    print(\"hello\")\nprint('-' * 40)\n\nhello()\n\nFunction: hello is defined\n----------------------------------------\nstart\nhello\nend\n\n\n\n\n\n① - Pass arguments in the function\n② - Add args and kwargs in the wrapper function arguments\n③ - Call the function with the args and kwargs passed\n\ndef dec(func): \n    print(f\"Function: {func.__name__} is defined\")\n    def wrapper(*args,**kwargs): #②\n        print(\"start\") \n        func(*args,**kwargs) #③ \n        print(\"end\")\n    return wrapper\n\n@dec\ndef hello(x:str)-&gt;None:#①\n    \"\"\"concat hello with passed in string and print\"\"\"\n    print(f\"hello {x}\")\n\nhello('world')\n\nprint('-' * 40)\n\n#④\nprint(f\"Func. Name: {hello.__name__}\",sep='\\n')\nprint(f\"Docstring: {hello.__doc__}\",sep='\\n')\nprint(f\"Annotations: {hello.__annotations__}\",sep='\\n')\n\nFunction: hello is defined\nstart\nhello world\nend\n----------------------------------------\nFunc. Name: wrapper\nDocstring: None\nAnnotations: {}\n\n\n\n\n\nWhen we use a decorator, the function dec is replaced by the wrapper function. This means we loose most of the properties like name, docstring, annotations, etc. We can use functools.wraps, which takes a function used in a decorator and add the functionality of copying over the function names, docstrings, annotation, etc.\n\nprint(f\"Func. Name: {hello.__name__}\",sep='\\n')\nprint(f\"Docstring: {hello.__doc__}\",sep='\\n')\nprint(f\"Annotations: {hello.__annotations__}\",sep='\\n')\n\nFunc. Name: wrapper\nDocstring: None\nAnnotations: {}\n\n\n\nfrom functools import wraps \n\ndef dec(func): \n    print(f\"Function: {func.__name__} is defined\")\n    @wraps(func)\n    def wrapper(*args,**kwargs): #②\n        print(\"start\") \n        func(*args,**kwargs) #③ \n        print(\"end\")\n    return wrapper\n\n@dec\ndef hello(x:str)-&gt;None: #①\n    \"\"\"concat hello with passed in string and print\"\"\"\n    print(f\"hello {x}\")\n\nhello('world')\n\n#④\nprint(f\"Func. Name: {hello.__name__}\",sep='\\n')\nprint(f\"Docstring: {hello.__doc__}\",sep='\\n')\nprint(f\"Annotations: {hello.__annotations__}\",sep='\\n')\n\nFunction: hello is defined\nstart\nhello world\nend\nFunc. Name: hello\nDocstring: concat hello with passed in string and print\nAnnotations: {'x': &lt;class 'str'&gt;, 'return': None}\n\n\nReturning value from a decorated function\n\nfrom functools import wraps \n\ndef dec(func): \n    print(f\"Function: {func.__name__} is defined\")\n    @wraps(func)\n    def wrapper(*args,**kwargs): #②\n        print(\"start\") \n        result=func(*args,**kwargs) #①\n        print(\"end\")\n        return result #②\n    return wrapper\n\n@dec\ndef hello(x:str)-&gt;None: \n    \"\"\"concat hello with passed in string and print\"\"\"\n    print(f\"hello {x}\")\n    return 'hello'\n\nhello('world')\n\nFunction: hello is defined\nstart\nhello world\nend\n\n\n'hello'\n\n\nPassing value to a decorator function\n\nfrom functools import wraps \n\ndef dec(a,b): \n    def dec_decorator(func):\n        print(f\"Function: {func.__name__} is defined\")\n        @wraps(func)\n        def wrapper(*args,**kwargs): #②\n            print(f\"start:{a}\") \n            result=func(*args,**kwargs) #①\n            print(f\"end:{b}\")\n            return result #②\n        return wrapper\n    return dec_decorator\n\n@dec('a','b')\ndef hello(x:str)-&gt;None: \n    \"\"\"concat hello with passed in string and print\"\"\"\n    print(f\"hello {x}\")\n    return 'hello'\n\nhello('world')\n\nFunction: hello is defined\nstart:a\nhello world\nend:b\n\n\n'hello'\n\n\nExample of a decorator\n\nfrom functools import wraps\nfrom time import perf_counter\ndef timer(func):\n    @wraps(func)\n    def wrapper(*args,**kwargs):\n        start_time=perf_counter()\n        func(*args,**kwargs)\n        end_time=perf_counter()\n        print(f\"\\N{Greek Capital Letter Delta} {end_time-start_time:.4f} sec\")\n    return wrapper\n\n@timer\ndef process_list(n=10000):\n    return sum(range(n))\n\nprocess_list()\n\nΔ 0.0002 sec"
  },
  {
    "objectID": "posts/post-its/index.html",
    "href": "posts/post-its/index.html",
    "title": "Decorators",
    "section": "",
    "text": "This article is part of the “Day in life of a Data Scientist” series, sharing some of the real-world problems data scientist work on daily. The question: How do we measure the impact of launching of a machine learning the business metrics when A/B testing can’t be done due to operational constraints ?\nProblem:\nWe have developed an algorithm that helps agents perform outreach to maximize sales. Ideally, We would measure its impact using an A/B test, comparing the sales between agents using the model and those who aren’t. However, the operatinal challenges made running a A/B testing impractical.\nSolution:\nThe solution to this problem is to use Interrupted Time Series (ITS) analysis."
  },
  {
    "objectID": "posts/post-with-code/index.html#selecting-columns",
    "href": "posts/post-with-code/index.html#selecting-columns",
    "title": "Mastering Data Manipulation in Pandas: A Guide to Key SQL Operations",
    "section": "Selecting columns",
    "text": "Selecting columns\nTo select specific columns, use the .loc method with a list of column names. This approach offers flexibility in data analysis.\n\n(df\n .loc[:,['tip','sex']]\n .head()\n)\n\n\n\n\n\n\n\n\n\ntip\nsex\n\n\n\n\n0\n1.01\nFemale\n\n\n1\n1.66\nMale\n\n\n2\n3.50\nMale\n\n\n3\n3.31\nMale\n\n\n4\n3.61\nFemale\n\n\n\n\n\n\n\n\nTo select columns starting with ‘t’:\n\n(df\n .loc[:,[col for col in df.columns if col.startswith('t')]]\n .head()\n)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\ntime\n\n\n\n\n0\n16.99\n1.01\nDinner\n\n\n1\n10.34\n1.66\nDinner\n\n\n2\n21.01\n3.50\nDinner\n\n\n3\n23.68\n3.31\nDinner\n\n\n4\n24.59\n3.61\nDinner"
  },
  {
    "objectID": "posts/post-with-code/index.html#column-manipulation",
    "href": "posts/post-with-code/index.html#column-manipulation",
    "title": "Mastering Data Manipulation in Pandas: A Guide to Key SQL Operations",
    "section": "Column Manipulation",
    "text": "Column Manipulation\nUse the .assign method to create or modify columns:\nAdd a new column with a constant value: .assign(new_col=1) Add a new column based on existing columns: .assign(new_col=lambda x: x['col'] + 1) Update an existing column: .assign(old_col=lambda x: x['old_col'] + 1)\n\n(df\n .loc[:,['total_bill','tip','sex','day','time']]\n .assign(percentage_tip=lambda x:x['tip']/x['total_bill']) #Add new column\n .assign(tip=lambda x:x['tip']+1) # Update existing column \n .assign(count=1) #Add constant value \n .head()\n)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nday\ntime\npercentage_tip\ncount\n\n\n\n\n0\n16.99\n2.01\nFemale\nSun\nDinner\n0.059447\n1\n\n\n1\n10.34\n2.66\nMale\nSun\nDinner\n0.160542\n1\n\n\n2\n21.01\n4.50\nMale\nSun\nDinner\n0.166587\n1\n\n\n3\n23.68\n4.31\nMale\nSun\nDinner\n0.139780\n1\n\n\n4\n24.59\n4.61\nFemale\nSun\nDinner\n0.146808\n1"
  },
  {
    "objectID": "posts/post-with-code/index.html#filtering-rows",
    "href": "posts/post-with-code/index.html#filtering-rows",
    "title": "Mastering Data Manipulation in Pandas: A Guide to Key SQL Operations",
    "section": "Filtering Rows",
    "text": "Filtering Rows\nUse the .query method to filter rows:\n\n#Filter only transaction with more than 15% in tips\n(df\n .loc[:,['total_bill','tip','sex','day','time']]\n .assign(percentage_tip=lambda x:x['tip']/x['total_bill'])\n .query(\"percentage_tip&gt;.15\")\n .head()\n)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nday\ntime\npercentage_tip\n\n\n\n\n1\n10.34\n1.66\nMale\nSun\nDinner\n0.160542\n\n\n2\n21.01\n3.50\nMale\nSun\nDinner\n0.166587\n\n\n5\n25.29\n4.71\nMale\nSun\nDinner\n0.186240\n\n\n6\n8.77\n2.00\nMale\nSun\nDinner\n0.228050\n\n\n9\n14.78\n3.23\nMale\nSun\nDinner\n0.218539\n\n\n\n\n\n\n\n\nUsing variables in queries:\n\nper_tip=.15\n#using f-string to perform filtering\ndisplay(df\n .loc[:,['total_bill','tip','sex','day','time']]\n .assign(percentage_tip=lambda x:x['tip']/x['total_bill'])\n .query(f\"percentage_tip&gt;{per_tip}\")\n .head()\n)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nday\ntime\npercentage_tip\n\n\n\n\n1\n10.34\n1.66\nMale\nSun\nDinner\n0.160542\n\n\n2\n21.01\n3.50\nMale\nSun\nDinner\n0.166587\n\n\n5\n25.29\n4.71\nMale\nSun\nDinner\n0.186240\n\n\n6\n8.77\n2.00\nMale\nSun\nDinner\n0.228050\n\n\n9\n14.78\n3.23\nMale\nSun\nDinner\n0.218539\n\n\n\n\n\n\n\n\n\n#Filter only transactions happend on Sunday and Monday\n(df\n .loc[:,['total_bill','tip','sex','day','time']]\n .query(\"day.isin(['Sun','Mon'])\",engine='python')\n .head()\n)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nday\ntime\n\n\n\n\n0\n16.99\n1.01\nFemale\nSun\nDinner\n\n\n1\n10.34\n1.66\nMale\nSun\nDinner\n\n\n2\n21.01\n3.50\nMale\nSun\nDinner\n\n\n3\n23.68\n3.31\nMale\nSun\nDinner\n\n\n4\n24.59\n3.61\nFemale\nSun\nDinner"
  },
  {
    "objectID": "posts/post-with-code/index.html#window-functions",
    "href": "posts/post-with-code/index.html#window-functions",
    "title": "Mastering Data Manipulation in Pandas: A Guide to Key SQL Operations",
    "section": "Window Functions",
    "text": "Window Functions\nPerform advanced data manipulation with window functions:\n\n#Equivalent of row_number() over(partition by day order by total_bill asc) as row_number\n(df\n .assign(row_number=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day']).cumcount()+1)\n .sort_values(['row_number'])\n .head()\n)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nrow_number\n\n\n\n\n67\n3.07\n1.00\nFemale\nYes\nSat\nDinner\n1\n1\n\n\n172\n7.25\n5.15\nMale\nYes\nSun\nDinner\n2\n1\n\n\n149\n7.51\n2.00\nMale\nNo\nThur\nLunch\n2\n1\n\n\n92\n5.75\n1.00\nFemale\nYes\nFri\nDinner\n2\n1\n\n\n222\n8.58\n1.92\nMale\nYes\nFri\nLunch\n1\n2\n\n\n\n\n\n\n\n\nCalculate lead and lag values:\n\n#Equivalent of lag(total_bill) over(partition by day order by total_bill asc) as previous_bill\n(df\n .assign(row_number=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day']).cumcount()+1)\n .assign(prev_bill=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day'])['total_bill'].shift(1))\n .sort_values(['row_number'])\n .head()\n)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nrow_number\nprev_bill\n\n\n\n\n67\n3.07\n1.00\nFemale\nYes\nSat\nDinner\n1\n1\nNaN\n\n\n172\n7.25\n5.15\nMale\nYes\nSun\nDinner\n2\n1\nNaN\n\n\n149\n7.51\n2.00\nMale\nNo\nThur\nLunch\n2\n1\nNaN\n\n\n92\n5.75\n1.00\nFemale\nYes\nFri\nDinner\n2\n1\nNaN\n\n\n222\n8.58\n1.92\nMale\nYes\nFri\nLunch\n1\n2\n5.75\n\n\n\n\n\n\n\n\n\n#Equivalent of lead(total_bill) over(partition by day order by total_bill asc) as previous_bill\n(df\n .assign(row_number=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day']).cumcount()+1)\n .assign(next_bill=lambda x:x.sort_values(['total_bill'],ascending=[True]).groupby(['day'])['total_bill'].shift(-1))\n .sort_values(['row_number'])\n .head()\n)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nrow_number\nnext_bill\n\n\n\n\n67\n3.07\n1.00\nFemale\nYes\nSat\nDinner\n1\n1\n7.25\n\n\n172\n7.25\n5.15\nMale\nYes\nSun\nDinner\n2\n1\n8.77\n\n\n149\n7.51\n2.00\nMale\nNo\nThur\nLunch\n2\n1\n7.56\n\n\n92\n5.75\n1.00\nFemale\nYes\nFri\nDinner\n2\n1\n8.58\n\n\n222\n8.58\n1.92\nMale\nYes\nFri\nLunch\n1\n2\n10.09\n\n\n\n\n\n\n\n\n\n#Equivalent of sum(total_bill) over(partition by day) as sum_bill_day\n#Equivalent of sum(tip) over(partition by day order by total_bill asc) as cum_tip_day\n#Equivalent of sum(tip) over(partition by day order by total_bill rows between 3 preceeding and current row) as rolling_3d_sum \n\n(df\n .assign(sum_bill_day=lambda x:x.groupby(['day'])['total_bill'].transform('sum'))\n .assign(cum_tip_day=lambda x:x.sort_values(['total_bill']).groupby(['day'])['tip'].cumsum())\n .assign(rolling_3d_sum=lambda x:x.sort_values(['total_bill']).groupby(['day'])['tip'].rolling(window=2,min_periods=1).sum().reset_index(drop=True, level=0))\n .query(\"day=='Sat'\")\n .sort_values(['total_bill'])\n .head()\n)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nsum_bill_day\ncum_tip_day\nrolling_3d_sum\n\n\n\n\n67\n3.07\n1.00\nFemale\nYes\nSat\nDinner\n1\n1778.4\n1.00\n1.00\n\n\n111\n7.25\n1.00\nFemale\nNo\nSat\nDinner\n1\n1778.4\n2.00\n2.00\n\n\n218\n7.74\n1.44\nMale\nYes\nSat\nDinner\n2\n1778.4\n3.44\n2.44\n\n\n30\n9.55\n1.45\nMale\nNo\nSat\nDinner\n2\n1778.4\n4.89\n2.89\n\n\n235\n10.07\n1.25\nMale\nNo\nSat\nDinner\n2\n1778.4\n6.14\n2.70"
  }
]